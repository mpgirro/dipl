
Bibliography : dipl
Bib Style    : ../style/keynat.bst
Cite All     : False

CSS Header      :
  @import url(https://fonts.googleapis.com/css?family=Crimson+Text);
  body.madoko {
    font-family: "Crimson Text", serif;
  }
  .madoko .math-rendering {
    color: black;
  }
  hr.figureline.madoko {
    display: none;
  }
  .toc a, .toc a:visited { 
    color: #0000EE;  
  }

.important {
  color:red
}
.Mind {
  background-color: #cbffcb;
  before="[";
  after="]"
}

[TOC]

# [@Agh85] Concurrent Programming Using Actors: Exploiting Large-Scale Parallelism

* no consenus has emerged on a single model of concurrency
* discussion on paradigm shift in [Pratt 83]
* "Pratt's Process Model" satisfies several properties desirable in any model of concurrent
  computation
* (Pratts?) model does not assume the existance of global states
* laws of parallel processing formulated in [Hewit and Baker 77]
* Foundational Issues (p.3-4 genauer erklärt)
  - Shared Resources
  - Dynamic Reconfiguration
  Inherent Parallelism
* Actor = computational agent which caries out its actions in response to accepting a communication
* Actions are:
  - Send communication to itself or to other actors
  - Create more actors (gibt es einen MSA mechanismus der das erlaubt? Cloud management frameworks
    nicht von MS direkt angesprochen)
  - Specify the replacement behaviour
* The buffering of communication has the consequence that actor languages support recursion.
  In languages relying on synchronous communication, any recursive procedure immediately leads to deadlock (!)
* Two important obersavtions need to be made about replacement. First, replacement implements
  local state chance while preserving referential transparency of the identifiers used in a program
* [...] computation of a replacement actor is an action which may be carried out concurrently with
  other actions performaed by an actor, the replacement process is intrinsically concurrent
* In actor-based architectures, the only constraints on the speed of execution stem from the
  logical dependencies in the computation and the limitations imposed by the hardware resources
* [...] this has the implicastio that message-passing can be used to spawn concurrency: An Actor,
  in response to a communciation, may send several communications to other actors
* A "configuration" (p.7) is a instantaneous snapshot og an actor system from some viewpoint. Each
  configuration has teh following parts:
  - local state function
  - set of unprocessed tasks
  - subset of the population, called "receptionist" actors
  - set of external actors
* Open Systems (p.16)
  It is reasonable to expect that large-scale parallel systems will be composed of independently developed and maintained modules. Such systems will be open-ended and continually undergoing change [Hewitt and de Jong 85]
* Characteristics of Open Systems
  - Continuous Availability
  - Modularity
  - Extensibility
* "Definition: Composition. Let c1 || c2 represent the concurrent composition..." (p.19)
* Actor languages uniformly use message-passing to spawn concurrency and are inherently parallel
* The problem of shared resources with changing local state is dealt with by providing an
  object-oriented environment without the sequential bottle-neck caused by assignment commands
* An actor language also provides a suitable basis for large-scale parallelism. Besides the
  ability to distribute the work required in the course of a computation, actor systems can be composed simply by passing messages between them. The internal workings of an actor system are not available to any other system

# [@Agh90] Concurrent Object-Oriented Programming

* p.126: Concurrency abstracts away some of the details in an execution, allowing us to concentrate on conceptual issues without having to be concerned with a particular order of execution which may result from the quirks of a given system. -- Highlighted 19 May 2017
* p.126: Objects can be defined as entities which encapsula.te data and operations into a single computational unit.  -- Highlighted 19 May 2017
* p.126: hree common patterns of parallelism in problems have been found in practice (For example, see [8, 131). First, pipeline concurrency involves the enumeration of potential solutions and the concurrent testing of these solutions as they are enumerated. Second, divide and conquer concurrency involves the concurrent elaboration of different subproblems and the joining of (some or all) of their solutions in order to obtain a solution to the overall problem. In divide and conquer concurrency, there is no interaction between the procedures solving the subproblems.  -- Highlighted 19 May 2017
* The term Actor was introduced by Carl Hewitt at MIT in the early 1970s
* p.127: Divide-and-conquer concurrency algorithms can often be expressed as functions.  -- Highlighted 19 May 2017
* p.128: n cooperative problem solving concurrency, intermediate results arestored in objects and shared by pass-ing messages between objects. -- Highlighted 19 May 2017
* p.128: Another example of coopera-tive problem solving is blackboardsystems which allow collaborationbetween agents through a sharedwork space. -- Highlighted 19 May 2017
* p.128: Actors are self-contained, interactive, independent componentsof a computing system that communicate by asynchronous message passing.  -- Highlighted 19 May 2017
* p.128: Each time an actor processes a communication, it also computes its behavior in response to the next communication it may process.  -- Highlighted 19 May 2017
* p.128: In other cases, the behavior may change. The change in the behavior may represent a simple change of state variables, such as change in the balance of an account, or it may represent changes in the operations (methods) which are carried out in response to messages. -- Highlighted 19 May 2017
* p.128: Concurrent computations can be visualized in terms of event diagrams (see Figure 5). These diagrams were developed to model the behavior of actor systems. -- Highlighted 19 May 2017
* p.130: A customer can be sent a reply message when a request is completed, or a complaint message if it is not possible to successfully complete the reqluest. -- Highlighted 19 May 2017
* p.132: Although actors take a functionalview of an object’s internal behavior at any given point in time, actors can represent shared history-sensitive ob-jects.  -- Highlighted 19 May 2017
* p.132: We call such a merge afair merge. Afair merge is complete because itmerges message:; from every senderand may not ignore any sender inde-finitely and it is indeterminate be-cause no particular order is specifiedfor messages sent to the same objectby different objects.  -- Highlighted 19 May 2017
* Using a semantics of fair merge, one can reason about the eventual behavior of a concurrent program; reasoning about eventual properties of a concurrent system is analogous to reasoning about fixed points in a recursion in sequential programming.
* Inherent Concurrency

# [@Akka17] Akka documentation

* Terminology, Concepts of:
  * Concurrency vs. Parallelism
  * Asynchronous vs. Synchronous
  * Non-blocking vs. Blocking
  * Deadlock vs. Starvation vs. Live-lock
  * Race Condition
  * Non-blocking Guarantees (Progress Conditions)
    * Wait-freedom
    * Lock-freedom
    * Obstruction-freedom
* Actor Systems
  * Actors are objects which encapsulate state and behavior, they communicate exclusively by exchanging messages
  * [An ActorSystem is a heavyweight structure that will allocate 1…N Threads, so create one per logical application]{.important}
  * The quintessential feature of actor systems is that tasks are split up and delegated until they become small enough to be handled in one piece
  * In doing so, not only is the task itself clearly structured, but the resulting actors can be reasoned about in terms of which messages they should process, how they should react normally and how failure should be handled
  * Compare this to layered software design which easily devolves into defensive programming with the aim of not leaking any failure out: if the problem is communicated to the right person, a better solution can be found than if trying to keep everything “under the carpet”.
  * Now, the difficulty in designing such a system is how to decide who should supervise what. There is of course no single best solution, but there are a few guidelines which might be helpful:
    * If one actor manages the work another actor is doing, e.g. by passing on sub-tasks, then the manager should supervise the child. The reason is that the manager knows which kind of failures are expected and how to handle them.
    * If one actor carries very important data (i.e. its state shall not be lost if avoidable), this actor should source out any possibly dangerous sub-tasks to children it supervises and handle failures of these children as appropriate. Depending on the nature of the requests, it may be best to create a new child for each request, which simplifies state management for collecting the replies. [This is known as the “Error Kernel Pattern” from Erlang]{.important}.
    * If one actor depends on another actor for carrying out its duty, it should watch that other actor’s liveness and act upon receiving a termination notice. This is different from supervision, as the watching party has no influence on the supervisor strategy, and it should be noted that a functional dependency alone is not a criterion for deciding where to place a certain child actor in the hierarchy.
  * The actor system as a collaborating ensemble of actors is the natural unit for managing shared facilities like scheduling services, configuration, logging, etc. Several actor systems with different configuration may co-exist within the same JVM without problems, there is no global shared state within Akka itself. Couple this with the transparent communication between actor systems—within one node or across a network connection—to see that actor systems themselves can be used as building blocks in a functional hierarchy
  * Actor Best Practices
    * process events and generate responses (or more requests) in an event-driven manner. Actors should not block (i.e. passively wait while occupying a Thread) on some external entity—which might be a lock, a network socket, etc.—unless it is unavoidable; in the latter case see below.
    * Do not pass mutable objects between actors. In order to ensure that, prefer immutable messages. If the encapsulation of actors is broken by exposing their mutable state to the outside, you are back in normal Java concurrency land with all the drawbacks.
    * Actors are made to be containers for behavior and state, embracing this means to not routinely send behavior within messages (which may be tempting using Scala closures). One of the risks is to accidentally share mutable state between actors, and this violation of the actor model unfortunately breaks all the properties which make programming in actors such a nice experience.
    * Top-level actors are the innermost part of your Error Kernel, so create them sparingly and prefer truly hierarchical systems. This has benefits with respect to fault-handling (both considering the granularity of configuration and the performance) and it also reduces the strain on the guardian actor, which is a single point of contention if over-used
  * actors are represented to the outside using actor references, which are objects that can be passed around freely and without restriction. [This split into inner and outer object enables transparency for all the desired operations: restarting an actor without needing to update references elsewhere, placing the actual actor object on remote hosts, sending messages to actors in completely different applications. But the most important aspect is that it is not possible to look inside an actor and get hold of its state from the outside, unless the actor unwisely publishes this information itself.]{.important}
  * State
    * These data are what make an actor valuable, and they must be protected from corruption by other actors. The good news is that Akka actors conceptually each have their own light-weight thread, which is completely shielded from the rest of the system. [This means that instead of having to synchronize access using locks you can just write your actor code without worrying about concurrency at all.]{.important}
    * Because the internal state is vital to an actor’s operations, having inconsistent state is fatal. Thus, when the actor fails and is restarted by its supervisor, the state will be created from scratch, like upon first creating the actor. This is to enable the ability of self-healing of the system.
  * Behaviour
    * Every time a message is processed, it is matched against the current behavior of the actor. Behavior means a function which defines the actions to be taken in reaction to the message at that point in time, say forward a request if the client is authorized, deny it otherwise. This behavior may change over time, e.g. because different clients obtain authorization over time, or because the actor may go into an “out-of-service” mode and later come back. These changes are achieved by either encoding them in state variables which are read from the behavior logic, or the function itself may be swapped out at runtime, see the become and unbecome operations. However, the initial behavior defined during construction of the actor object is special in the sense that a restart of the actor will reset its behavior to this initial one.
  * Mailbox
    * Enqueuing happens in the time-order of send operations, which means that messages sent from different actors may not have a defined order at runtime due to the apparent randomness of distributing actors across threads. Sending multiple messages to the same target from the same actor, on the other hand, will enqueue them in the same order.
    * An important feature in which Akka differs from some other actor model implementations is that the current behavior must always handle the next dequeued message, there is no scanning the mailbox for the next matching one. Failure to handle a message will typically be treated as a failure, unless this behavior is overridden.
  * Supervision and Monitoring
    * [dependency relationship between actors: the supervisor delegates tasks to subordinates and therefore must respond to their failures]{.important}
    * Depending on the nature of the work to be supervised and the nature of the failure, the supervisor has a choice of the following four options:
      1. Resume the subordinate, keeping its accumulated internal state
      2. Restart the subordinate, clearing out its accumulated internal state
      3. Stop the subordinate permanently
      4. Escalate the failure, thereby failing itself
    * It is important to always view an actor as part of a supervision hierarchy, which explains the existence of the fourth choice (as a supervisor also is subordinate to another supervisor higher up) and has implications on the first three: resuming an actor resumes all its subordinates, restarting an actor entails restarting all its subordinates (but see below for more details), similarly terminating an actor will also terminate all its subordinates
    * [Akka implements a specific form called “parental supervision”. Actors can only be created by other actors—where the top-level actor is provided by the library—and each created actor is supervised by its parent. This restriction makes the formation of actor supervision hierarchies implicit and encourages sound design decisions. It should be noted that this also guarantees that actors cannot be orphaned or attached to supervisors from the outside, which might otherwise catch them unawares. In addition, this yields a natural and clean shutdown procedure for (sub-trees of) actor applications.]{.important} [in MSA werden die MS idR schon von außen (vom menschen - oder einem deployment tool erzeugt, dh es kann hier sehrwohl zu "unsound decisions" kommenbat)]{.mind}
  * What Restarting Means
    * When presented with an actor which failed while processing a certain message, causes for the failure fall into three categories:
      * Systematic (i.e. programming) error for the specific message received
      * (Transient) failure of some external resource used during processing the message
      * Corrupt internal state of the actor
    * Unless the failure is specifically recognizable, the third cause cannot be ruled out, which leads to the conclusion that the internal state needs to be cleared out. If the supervisor decides that its other children or itself is not affected by the corruption—e.g. because of conscious application of the error kernel pattern—it is therefore best to restart the child
  * What Lifecycle Monitoring Means
    * Lifecycle Monitoring in Akka is usually referred to as DeathWatch
    * In contrast to the special relationship between parent and child described above, each actor may monitor any other actor. Since actors emerge from creation fully alive and restarts are not visible outside of the affected supervisors, the only state change available for monitoring is the transition from alive to dead. [Monitoring is thus used to tie one actor to another so that it may react to the other actor’s termination, in contrast to supervision which reacts to failure.]{.important}
  * Actor References, Paths and Addresses
    * describes how actors are identified and located within a possibly distributed actor system. It ties into the central idea that Actor Systems form intrinsic supervision hierarchies as well as that [communication between actors is transparent with respect to their placement across multiple network nodes.]{.important}
    * several different types of actor references that are supported depending on the configuration of the actor system:
      * pureley local
      * local (networking inside the same JVM)
      * remote (reachable using remote communication, i.e. sending messages to them will serialize the messages transparently and send them to the remote JVM.)
      * others more special and not so interrestingly
  * Location Transparency
    * Distributed by Default
      * Everything in Akka is designed to work in a distributed setting: all interactions of actors use purely message passing and everything is asynchronous. This effort has been undertaken to ensure that all functions are available equally when running within a single JVM or on a cluster of hundreds of machines. The key for enabling this is to go from remote to local by way of optimization instead of trying to go from local to remote by way of generalization. See this classic paper for a detailed discussion on why the second approach is bound to fail.
  * Ways in which Transparency is Broken
    * distributed execution poses some restrictions on what is possible
    * all messages sent over the wire must be serializable
    * everything needs to be aware of all interactions being fully asynchronous, which in a computer network might mean that it may take several minutes for a message to reach its recipient (depending on configuration). [It also means that the probability for a message to be lost is much higher than within one JVM, where it is close to zero (still: no hard guarantee!).]{.important}
  * Peer-to-Peer vs. Client-Server
    * The design of remoting is driven by two (related) design decisions
      1. Communication between involved systems is symmetric: if a system A can connect to a system B then system B must also be able to connect to system A independently.
      2. role of the communicating systems are symmetric in regards to connection patterns: there is no system that only accepts connections, and there is no system that only initiates connections.
    * [The consequence of these decisions is that it is not possible to safely create pure client-server setups with predefined roles (violates assumption 2)]{.important}. For client-server setups it is better to use HTTP or Akka I/O.
    * Important: Using [setups involving Network Address Translation, Load Balancers or Docker containers violates assumption 1]{.important}, unless additional steps are taken in the network configuration to allow symmetric communication between involved systems. In such situations Akka can be configured to bind to a different network address than the one used for establishing connections between Akka nodes
  * Marking Points for Scaling Up with Routers
    * In addition to being able to run different parts of an actor system on different nodes of a cluster, it is also possible to scale up onto more cores by multiplying actor sub-trees which support parallelization. 
    * The clones can then be routed to in different fashions, e.g. round-robin
  * Akka and the Java Memory Model
    * TODO
  * Message Delivery Reliability
    * Akka helps you build reliable applications which make use of multiple processor cores in one machine (“scaling up”) or distributed across a computer network (“scaling out”)
    * The key abstraction to make this work is that all interactions between your code units—actors—happen via message passing
    * The basic mechanism for communication is the same whether sending to an actor on the local JVM or to a remote actor, but of course there will be observable differences in the latency of delivery (possibly also depending on the bandwidth of the network link and the message size) and the reliability
    * In case of a remote message send there are obviously more steps involved which means that more can go wrong. 
    * Another aspect is that local sending will just pass a reference to the message inside the same JVM, without any restrictions on the underlying object which is sent, whereas a remote transport will place a limit on the message size.
    * Writing your actors such that every interaction could possibly be remote is the safe, pessimistic bet. It means to only rely on those properties which are always guaranteed and which are discussed in detail below
    * General Rules
      * at-most-once delivery, i.e. no guaranteed delivery
      * message ordering per sender–receiver pair
      * The first rule is typically found also in other actor implementations while the second is specific to Akka.
    * Discussion: Why No Guaranteed Delivery?
      * At the core of the problem lies the question what exactly this guarantee shall mean:
        1. The message is sent out on the network?
        2. The message is received by the other host?
        3. The message is put into the target actor’s mailbox?
        4. The message is starting to be processed by the target actor?
        5. The message is processed successfully by the target actor? 
      * Along those same lines goes the reasoning in [Nobody Needs Reliable Messaging](https://www.infoq.com/articles/no-reliable-messaging). The only meaningful way for a sender to know whether an interaction was successful is by receiving a business-level acknowledgement message, which is not something Akka could make up on its own (neither are we writing a “do what I mean” framework nor would you want us to).
      * Akka embraces distributed computing and makes the fallibility of communication explicit through message passing, therefore it does not try to lie and emulate a leaky abstraction. This is a model that has been used with great success in Erlang and requires the users to design their applications around it. You can read more about this approach in the [Erlang documentation (section 10.9 and 10.10)](http://erlang.org/faq/academic.html), Akka follows it closely.
    * Higher-level abstractions
      * Messaging Patterns
        * As discussed above a straight-forward answer to the requirement of reliable delivery is an explicit ACK–RETRY protocol. In its simplest form this requires
          * a way to identify individual messages to correlate message with acknowledgement
          * a retry mechanism which will resend messages if not acknowledged in time
          * a way for the receiver to detect and discard duplicates
        * The third becomes necessary by virtue of the acknowledgements not being guaranteed to arrive either. An ACK-RETRY protocol with business-level acknowledgements is supported by At-Least-Once Delivery of the Akka Persistence module. Duplicates can be detected by tracking the identifiers of messages sent via At-Least-Once Delivery. Another way of implementing the third part would be to make processing the messages idempotent on the level of the business logic.
      * Event Sourcing
        * Event sourcing (and sharding) is what makes large websites scale to billions of users, and the idea is quite simple: when a component (think actor) processes a command it will generate a list of events representing the effect of the command. These events are stored in addition to being applied to the component’s state. The nice thing about this scheme is that events only ever are appended to the storage, nothing is ever mutated; this enables perfect replication and scaling of consumers of this event stream (i.e. other components may consume the event stream as a means to replicate the component’s state on a different continent or to react to changes). If the component’s state is lost—due to a machine failure or by being pushed out of a cache—it can easily be reconstructed by replaying the event stream (usually employing snapshots to speed up the process). Event sourcing is supported by Akka Persistence.
      * Mailbox with Explicit Acknowledgement
        * By implementing a custom mailbox type it is possible to retry message processing at the receiving actor’s end in order to handle temporary failures. This pattern is mostly useful in the local communication context where delivery guarantees are otherwise sufficient to fulfill the application’s requirements.


# [@Als16] A Systematic Mapping Study in Microservice Architecture

  * Mache ich auch eine "Mapping Study"?
  * The microservices architecture has become a dominant architectural style choice in the service oriented software industry. Microservices is a style of architecture which puts the emphasis on dividing the system into small and lightweight services that are purposely built to perform a very cohesive business function, and is an evolution of the traditional service oriented architecture style
  * a distributed application where all its modules are microservices
  * commonly agreed benefits:
    * increase in agility
    * developer productivity
    * resilience
    * scalability* reliability
    * maintainability
    * separation of concerns
    * ease of development
  * Even though microservices have emerged from the software industry and have been the focus of practitioners in the last decade[28][22], academic researchers have not kept with the pace
  * Relevante keywords (werden auch für mich irgendwie relevant sein)
    * Communication/Integration
    * Service discovery
    * Performance
    * Fault-tolerance
    * Security
    * Tracing and Logging
    * Application Performance Monitoring* Deploying operations
  * Quality Attributes:
    * Scalability: expandable, evolutionary
    * Interestingly, it has been noticed that there was no distinction between component diagrams and container diagrams in the literature
    * Maintainability: reducing complexity, isolation, loose coupling , decouple, distributed, containerization, autonomy
    * Deployment: expandable, adaptability, changeability, flexible implementation, dynamically changing
    * Health management: resilience, reliability, disaster recovery, no single point of failure
    * Modularity: single responsibility, reduce complexity, separate business concern, specialization, customizable
    * Manageability: self-managed, decentralized management, audibility
    * Performance: response times, transaction duration, throughput, efficiency
    * Reusability: pluggable
    * Technology heterogeneity: portability, freedom to choose a lot of technologies or programming languages
    * Independence: reducing complexity, isolation, loose coupling , decouple, distributed, containerization, autonomy
    * Technology heterogeneity: portability, freedom to choose a lot of technologies or programming languages
    * Agility: iterative, incremental, continuous delivery
    * Security
    * Load balancing: workload intensity distribution
    * Organizational alignment: cross-functional team, reduce the conflict between developers and testers
    * Open interface: microservices should provide an open description of their APIs, GUIs and communication messages format

# [@Anc16] Behavioral Types in Programming Languages

* Modern society is increasingly dependent on large-scale software sys-tems that are distributed, collaborative and communication-centered.
* Correctness and reliability of such systems depend on compatibility between components and services that are newly developed or may al-ready exist.
* Current software de-velopment technology is not well suited to producing these large-scale systems, because of the lack of high-level structuring abstractions for complex communication behavior.
* A recent trend in current research is to use behavioral type the-ory as the basis for new foundations, programming languages, and software development methods for communication-intensive distributed systems.
* Behavioral type theory encompasses concepts such as inter-faces, communication protocols, contracts, and choreography. Roughly speaking, a behavioral type describes a software entity, such as an ob-ject, a communication channel, or a Web Service, in terms of the se-quences of operations that allow for a correct interaction among the involved entities.
* Chapter 2 is devoted to the integration of behavioral types into Object-Oriented languages. Object-oriented languages are rele-vant for their widespread adoption in the current development of software, for the wealth and popularity of tools that are avail-able, and because objects nicely fit a distribution model to which behavioral types can be applied naturally. The integration can be achieved in different ways: either by enriching the languages with constructs (in particular, sessions) that call for a correspond-ing extension at the type level, or by amalgamating sessions and objects to the point that the objects themselves become the enti-ties for which a behavioral description is required, for example to specify the order in which methods must/can be invoked.
* The WSDL and UDDI standards are technologies currently en- abling the description of Web Service interfaces and the creation of Web Service repositories. Chapter 7 explores the potential of behavioral types, intended as abstract descriptions of Web Ser-vice behaviors, as natural generalizations of WSDL interfaces to realize sophisticated forms discovering, composition, and orches-tration of Web Services.
* Chapter 8 illustrates the design-by-contract methodology for the development of possibly distributed, communicating systems. Ac-cording to this methodology, behavioral types are used for de-scribing, from a vantage point of view, the topology of the com-munication network, the communications that are supposed to occur, and in which order. Such global specifications serve multi-ple purposes: they are a valuable form of abstract specification of the overall behavior of a distributed system; they can be projected for describing the local behavior of the network participants to allow the modular type checking of complex systems; they enable the generation of monitors to verify, at runtime, that the partici-pants of a heterogeneous distributed system behave as expected, even if only some or none of them have been type checked against their supposed or claimed behavior.
* Session types can be seen as a special case of typestate, in which the ordered operations are the sends and receives on communication channels.
* Delegation. Delegation, namely the act of communicating a channel as a message, works as in standard session types and it is modeled through the constructs:
* Service Oriented Computing (SOC) is based on services, intended as autonomous and heterogeneous components that can be published and discovered via standard interface languages and publish/discovery pro-tocols.Web Services is the most prominent service-oriented technology: Web Services publish their interface expressed in the Web Service De-scription Language (WSDL), they are discovered through the UDDI protocol, and they are invoked using SOAP.
* Services are often developed as combination of other existing services, by using so-called orchestration languages, such as WS-BPEL [OASIS, 2007]: executable languages which perform activities by means of local computations combined with invocations to other services.
* Session type theories make it possible to extract such behavioral descriptions (in the form of types) from the actual service code (type inference) or to check that service code conforms to a given behavioral description (type checking).
* In turn, type checking crucially relies on the notion of duality (correspondence of invokes and receives), guaran-teeing service compliance in an interaction involving multiple services, and on a sub-typing relation between session types (see compliance test-ing preorder [Bravetti and Zavattaro, 2007, 2008b]). The sub-typing relation is defined to be the coarsest one that preserves the desired termination properties, so to be as permissive as possible when typing code (we will discuss these aspects with examples in §7.3). This form of sub-typing, called semantic sub-typing, is more permissive compared to the syntactic ones commonly adopted in session types, and plays a key role in addressing the problem of service discovery.
* In order to be able to perform this kind of checks, it is necessary for services to expose in their interface also the description of their be-havior (obtained, as we mentioned, by applying the type system on the service code).
* In general, a service interface description language used in directory services like UDDI can expose both static and dynamic information about Web Services. The former deals with the signature (name and type of the parameters) of the invocable operations; the latter deals with the correct order of invocation of the provided operations in order to correctly complete a session of interaction.
* Concrete orchestrations are presented to show how services can be programmed in terms of invoca-tions of other services and as a starting point to then extract abstract orchestrations, used to express and reason about interaction with other services.
* Jolie (Java Orchestration Lan- guage Interpreter Engine) is a general-purpose programming language based on the Service-Oriented Computing paradigm [Montesi et al., 2014, development team]. It was originally presented by Montesi et al. [2007] as an orchestration language forWeb Services alternative to the standard language WS-BPEL, with the advantage of being based on formal models from the start and consequently enabling abstract rea- soning on the behavior of Jolie programs; this is in contrast with WS- BPEL, whose reference implementations are based on informal specifi- cations
* Other advantages of Jolie are that it is equipped with a friendly syntax similar to C/Java and that it integrates behavioral primitives for orchestration with architectural primitives for programming the or- ganization of a network
* the result of this integration is that these architectural primitives can be used to set up, e.g., load balancers, proxies, or monitors that can be reused independently of the orchestration behavior of the services that they compose, or even in settings where different communication technologies or protocols are used (e.g., HTTP instead of SOAP).
* Jolie is also equipped with a rather sophis-ticated fault handling mechanism [Guidi et al., 2009]: compensation handlers can be dynamically updated taking under consideration infor-mation available only at runtime.
* Moreover, if a fault occurs during a bidirectional request-response interaction, the correct interruption and compensation of both communicating processes is guaranteed.
* Despite Jolie was initially designed as a language for Web Services orchestra-tion, during its development the language has evolved to a general-purpose tool that can be applied to different scenarios, from multi-core computing to web applications [Montesi, 2013a, Montesi et al., 2014].
* As we already mentioned, using a process algebraic approach, it is possible to define how to extract the externally observable behavior (behavioral contract/session type) from the actual executable behavior of a service [Boreale and Bravetti, 2011].
* is then enough informative to enable analysis of certain properties of the actual service (when interacting with other services), including stuck freedom [Fournet et al., 2004], deadlock freedom [Castagna et al., 2009], termination (under fairness assumptions) [Bravetti and Zavattaro, 2007, 2008a,b]. In particular, such analysis is often carried out by resorting to more low-level se-mantic descriptions of service behaviors (essentially labeled transition systems) called behavioral contracts.
* One of the most important as-pects of the service contract technology is considered to be *correctness of composition*  or, more simply, compliance: given any set of services, it should be possible to prove that their composition is correct (accord-ing to the above mentioned termination properties) knowing only their contracts, i.e. in the absence of complete knowledge about the internal details of the services behavior.
* We exemplify abstract process representation by providing the de-scription of the Customer-Agency use case with abstract WS-BPEL. In order to avoid writing obscure and verbose XML code we adopt the more intuitive notation of BPELscript.
* A recent line of research advocates the development of safe distributed systems with Choreographic Programming, a programming paradigm in which developers write system implementations using choreogra-phies.
*  Implementation challenges:
  * The first challenge is supporting session communications. In gen-eral, a session may have many participating processes, which need to be able to communicate with each other at runtime.
  * Since Chor uses a service-oriented lan-guage such as Jolie, the public channel is actually implemented as an always-available service that can be used by processes in the network to create new sessions [Montesi, 2013b] (each public channel has its own service implementation).
  * The second challenge is the integration with existing paradigms. Language models for choreographies typically focus on minimality and give only a high-level description of how the code compiled from a choreography should behave. Typically, these models are inspired to the π-calculus [Sangiorgi and Walker, 2001] in order to facilitate their formal investigation.
  * However, all communications in service-oriented comput-ing happen over operations and thus this change is a necessary addition when compiled code is to be executed in a service-oriented architecture.
  * Different modifications would be needed for other paradigms; in gen-eral, they should be made with particular care, since any changes to the original theoretical models of choreographic programming risk breaking their safety properties (e.g., deadlock-freedom).
  * the third challenge is about reliability. To the best of our knowledge, all implemented choreography languages work on the as-sumption that communications will succeed (the network is “perfect”) and execution units never fail.
  * Therefore, the safety properties of chore-ographies are guaranteed only if these assumptions are not broken at runtime.

# [@Bla13] Object-oriented programming: Some history, and challenges for the next fifty years

* [...] Alan Snyder of Hewlett Packard wrote an influential survey paper “The Essence of Objects”
* In Snyder’s view, the essential concepts were as follows:
  - An object embodies an abstraction.
  - Objects provide services.
  - Clients issue requests for those services.
  - Objects are encapsulated.
  - Requests identify operations.
  - Requests can identify objects.
  - New objects can be created.
  - The same operation on distinct objects can have different implementations and observably different behaviour.
  - Objects can be classified in terms of their services (interface hierarchy).
  - Objects can share implementations.
    – Objects can share a common implementation (multiple instances).
    – Objects can share partial implementations (implementation inheritance or delegation).
* Snyder does mention “Active Objects” as an “associated concept,” that is, an idea “associated with the notion of objects, but not essential to it.” The idea that classes can serve as modules does not appear at all.
* Dan Ingalls’ sweeping 1981 Byte article “Design Principles behind Smalltalk” [27]
* In 2002, Dahl wrote [14]:
  The most important new concept of Simula 67 is surely the idea of data structures with associated operators . . . called objects. There is an important difference, except in trivial cases, between
  - the inside view of an object, understood in terms of local variables, possibly initialising operations establishing an
invariant, and implemented procedures operating on the variables maintaining the invariant, and
  - the outside view, as presented by the remotely accessible procedures, including some generating mechanism, dealing
with more “abstract” entities.
* Simula’s “quasi-parallelism” was a sweet-spot in 1961: it allowed programmers to think about concurrency while ignoring synchronisation. Because another task could execute only when explicitly resumed, programmers could be confident that their data would not change “out from under them” at unexpected times
* Hewitt’s Actor model [37] built on this idea, as did Emerald [16], in which every object could potentially contain a process. Other languages, like Erlang, have made the process the main focus of the language rather than the object [38].

# [@Bri87] Inheritance and Synchronization in Concurrent OOP

  * Knowledge sharing (or inheritance) is a mechanism intensively used in OOP. Its basic idea is the reuse of object descriptions.
  * The second advantage is the introduction of classification among objects. It is used to hierarchically (or almost hierarchically) structuring knowledge, and it makes knowledge searching more efficient [Touretzky 861.
  * Delegation [Lieberman 86b] is another strategy we discuss as well. Delegation is discussed in the framework of the Actor model of computation (Hewitt 76,Lieberman 811.
  * (parallel) semantic network languages (e.g., NETL (Fahlman 791). [dieses quelle sollte ich mir zwecks literatur vermutlich anschauen]{.quelle}
  * Only the delegation scheme is flexible enough to be free from the shared memory assumption, so we will examine and criticize it in the distributed memory context. [MS haben inherent distributed memory]{.mind}
  * Flexibility versus Efficiency: This is one of the main tradeoffs in knowledge sharing.
  * Our main comment is that this inheritance scheme using hard-wired links is not suitable for distributed memory models. [hard-wired links = in-memory calls]{.mind}
  * The delegation scheme has been proposed in the Act-1 language [Lieberman 811. An object (called an actor in this computation model [Hewitt 761 where the class concept is absent) knows about another object called a prozy.
  * The delegation scheme enjoys the uniformity of the communication protocol: the delegation to the proxy of an object is performed by message passing, not by a system primitive through the hard-wired physical link (pointer).  [= in-memory call]{.mind}
  * Thus delegation can be fully designed at the user-language level and it can be locally customized by the user easily. This scheme is independent of the assumption of shared memory andis perfectly suitable for distributed (memory and computation) models. It also allows full dynamicity and modularity.
  * In examining this scheme, two issues, namely efficiency and synchronization, must be addressed. [Efficiency in MS hängt von Marshalling der Messages und dem network ab -> Performance von SOA]{.mind}
  * In the delegation scheme, variable consultation as well as method activation should be performed through message passing because both can be delegated to another object (the proxy).
  * Thus we first identify message passing with function call as in most of OOP extensions of Lisp. [msg passing == REST method call == function call]{.mind}
  * Each such variable-object owns the two methods that handle two kinds of messages: one to consult the variable (get), and the other to update it (set). [vgl. CRUD methoden bei REST]{.mind}
  * However in some concurrent models such as the Actor model, message passing is asynchronous and unidirectional. There is no implicit synchronization. AS a consequence, variable access is no more atomic and could be mishandled.
  * Message Ordering Issue [???]{.mind}
  * Fairness and Recursion: In an asynchronous message passing model, the messages sent to an object 0 are ordered (in a queue) following the ordering of their arrivals to 0. It is assumed that two messages cannot arrive at the same time.
  * We notice that the latest Actor model [Agha 851 relies on atomic objects. In this model, there is no side effect.
  * There is no delegation proposed in the Actor model of [Agha 85].
  * Bild des Delegation Schemas seite 38 [so ein bild sollte ich vll auch haben, da eine gateway ist immer delegation]{.mind}

# [@But14] Seven Concurrency Models in Seven Weeks: When Threads Unravel

* A concurrent program has multiple logical threads of control. These threads may or may not run in parallel.
* A parallel program potentially runs more quickly than a sequential program by executing different parts of the computation simultaneously (in parallel). It may or may not have more than one logical thread of control.
*  In a shared-memory multiprocessor, each processor can access any memory location, and interprocessor communication is primarily through memory, as you can see in Figure 1, Shared memory, on page 5.
* Figure 2, Distributed memory, on page 5 shows a distributed-memory system, where each processor has its own local memory and where interprocessor communication is primarily via the network.
* Because communicating via memory is typically faster and simpler than doing so over the network, writing code for shared memory-multiprocessors is generally easier. But beyond a certain number of processors, shared memory becomes a bottleneck—to scale beyond that point, you’re going to have to tackle distributed memory. Distributed memory is also unavoidable if you want to write fault-tolerant systems that use multiple machines to cope with hardware failures.
* Concurrency enables resilient, or fault-tolerant, software through indepen-dence and fault detection. Independence is important because a failure in one task should not be able to bring down another. And fault detection is critical so that when a task fails (because it crashes or becomes unresponsive, or because the hardware it’s running on dies), a separate task is notified so that it can take remedial action.
* Sequential software can never be as resilient as concurrent software.
* Threads and locks: Threads-and-locks programming has many well-under-stood problems, but it’s the technology that underlies many of the other models
* Functional programming: ... excellent support for concurrency and parallelism. Because they eliminate mutable state, functional programs are intrinsically thread-safe and easily parallelized.
* Actors: It can target both shared- and dis-tributed-memory architectures and facilitate geographical distribution
* Communicating Sequential Processes (CSP) has much in common with the actor model, both being based on message passing. Its emphasis on the channels used for communication, rather than the entities between which communication takes place

~ {color:red}
* Each of these models has a different sweet spot. As you read through each chapter, bear the following questions in mind:
  * Is this model applicable to solving concurrent problems, parallel problems, or both?
  * Which parallel architecture or architectures can this model target?
  * Does this model provide tools to help you write resilient or geographically distributed code?
~

* Threads
  * Despite their well-known problems, threads and locks are still the default choice for writing much concurrent software
  * Threads and locks are little more than a formalization of what the underlying hardware actually does. That’s both their great strength and their great weakness.

# [@Dra17a] Microservices: yesterday, today, and tomorrow

  * mainstream languages for development of server-side applications, like Java, C/C++, and Python, provide abstractions to break down the complexity of programs into modules. However, these languages are designed for the creation of single executable artefacts, also called monoliths
  * modules of a monolith depend on said shared resources, they are not independently executable
  * Definition 1 (Monolith): A monolith is a software application whose modules cannot be executed independently.
    * Issues:
      * I1: large-size monoliths are difficult to maintain and evolve due to their complexity. Tracking down bugs requires long perusals through their code base
      * I2: monoliths also suffer from the "dependency hell" [55], in which adding or updating libraries results in inconsistent systems that do not compile/run or, worse, misbehave
      * I3: any change in one module of a monolith requires rebooting the whole application. For large- sized projects, restarting usually entails considerable downtimes, hindering development, test- ing, and the maintenance of the project
      * I4: deployment of monolithic applications is usually sub-optimal due to conflicting requirements on the constituent models’ resources: some can be memory-intensive, others computational- intensive, and others require ad-hoc components (e.g., SQL-basedrather than graph-based databases).When choosing a deployment environment, the developer must compromise with a one-size-fits-all configuration, which is either expensive or sub-optimal with respect to the individual modules
      * I5: monoliths limit scalability. The usual strategy for handling increments of inbound requests is to create new instances of the same application and to split the load among said instances. However, it could be the case that the increased traffic stresses only a subset of the modules, making the allocation of the new resources for the other components inconvenient
      * I6: monoliths also represent a technology lock-in for developers, whichare boundto use the same language and frameworks of the original application
  * Definition 2 (Microservice): Amicroservice is a cohesive, independent process interacting via messages
  * From a technical point of view,microservices should be independent components conceptually deployed in isolation and equipped with dedicated memory persistence tools (e.g., databases)
  * Definition 3 (Microservice Architecture): Amicroservice architecture is a distributed application where all its modules are microservices
  * The microservice architectural style does not favour or forbid any particular programming paradigm. It provides a guideline to partition the components of a distributed application into independent entities, each addressing one of its concerns. This means that a microservice, provided it offers its functionalities via message passing, can be internally implemented with any of the mainstream languages cited in the beginning of this section.
  * The principle of microservice architectures assists project managers and developers: it provides a guideline for the design and implementation of distributed applications. Following this principle, developers focus on the implementation and testing of a few, cohesive functionali-ties. This holds also for higher-level microservices, which are concerned with coordinating the functionalities of other microservices.
  * Solutions (S1 is a solution to I1):
    * S1: microservices implement a limited amount of functionalities, which makes their code base small and inherently limits the scope of a bug.Moreover, since microservices are independent, a developer can directly test and investigate their functionalities in isolation with respect to the rest of the system
    * S2: it is possible to plan gradual transitions to new versions of a microservice. The new version can be deployed “next” to the old one and the services that depend on the latter can be gradually modified to interact with the former. This fosters continuous integration [32] and greatly eases software maintenance
    * S3: as a consequence of the previous item, changing a module of a microservice architecture does not require a complete reboot of the whole system. The reboot regards only the microservices of that module. Since microservices are small in size, programmers can develop, test, and maintain services experiencing only very short re-deployment downtimes
    * S4: microservices naturally lend themselves to containerisation [56], and developers enjoy a high degree of freedom in the configuration of the deployment environment that best suits their needs (both in terms of costs and quality of service)
    * S5: scaling a microservice architecture does not imply a duplication of all its components and de- velopers can conveniently deploy/dispose instances of services with respect to their load
    * S6: the only constraint imposed on a network of interoperating microservices is the technol- ogy used to make them communicate (media, protocols, data encodings). Apart from that, microservices impose no additional lock-in and developers can freely choose the optimal re- sources (languages, frameworks, etc.) for the implementation of each microservice
  * In software engineering, architecture is concerned with providing a bridge between system functionality and requirements for quality attributes that the system has to meet.
  * This spike of interest contributed to an increase in the number of existing software architecture patterns (or generally called styles), so that some form of classification was then required. This problem was tackled in one of the most notable works in the field, the book “Software Ar- chitecture: Perspectives on an Emerging Discipline” by Garlan and Shaw
  * The classic by Gamma et al. [36] covers the design of object-oriented software and how to translate it into code presenting a collection of recurring solutions, called patterns.
  * Attention to separation of concerns has recently led to the emergence of the so-calledComponent- based software engineering (CBSE)
  * The last decade has seen a further shift towards the concept of service first [81] and the natural evolution to microservices afterwards
  * Service-Oriented Computing (SOC) is an emerging paradigm for distributed computing and e-business processing that finds its origin in object-oriented and component computing
  * In SOC, a program — called a service — offers functionalities to other components, accessible via message passing
  * Services decouple their interfaces (i.e. how other services access their functionalities) from their implementation
  * The benefits of service-orientation are:
    * Dynamism - New instances of the same service can be launched to split the load onthe system;
    * Modularity and reuse - Complex services are composed of simpler ones. The same services can be used by different systems;
    * Distributed development - By agreeing on the interfaces of the distributed system, distinct development teams can develop partitions of it in parallel;
    * Integration of heterogeneous and legacy systems - Services merely have to implement standard protocols to communicate
  * The idea of componentization used in service-orientation can be partially traced back to the object-oriented programming (OOP) literature; however, there are peculiar differences that led to virtually separate research paths and communities. As a matter of fact, SOC at the origin was - and still is - built on top of OOP languages, largely due to their broad diffusion in the early 2000s
  * However, the evolution of objects into services, and the relative comparisons, has to be treated carefully since the first focus on encapsulation and information is hidden in a shared-memory scenario, while the second is built on the idea of independent deployment and message-passing. It is therefore a paradigm shift, where both the paradigms share the common idea of componentization
  * The next step is adding the notion of business capability and therefore focusing analysis and design on it so that the overall system architecture is determined on this basis
  * The first “generation” of service-oriented architectures (SOA) defined daunting and nebulous requirements for services (e.g., discoverability and service contracts), and this hindered the adop- tion of the SOA model
  * Microservices are the second iteration on the concept of SOA and SOC
  * The aim is to strip away unnecessary levels of complexity in order to focus on the programming of simple services that effectively implement a single functionality
  * Like OO, the microservices paradigm needs ad-hoc tools to support developers and naturally leads to the emergence of specific design patterns
  * First and foremost, languages that embrace the service-oriented paradigm are needed (instead, for the most part, microservice architectures still use OO lan- guages like Java and Javascript or functional ones). The same holds for the other tools for development support like testing suites, (API) design tools, etc.
  * The microservices architecture appeared lately as a new paradigm for programming applications by means of the composition of small services, each running its own processes and communicating via light-weight mechanisms
  * This approach has been built on the concepts of SOA [51] brought from crossing-boundaries workflows to the application level and into the applications architec- tures, i.e. its Service-Oriented Architecture and Programming from the large to the small.
  * The term “microservices” was first introduced in 2011 at an architectural workshop as a way to describe the participants’ common ideas in software architecture patterns [33]
  * Microservices now are a new trend in software architecture, which emphasises the design and development of highly maintainable and scalable software
  * Microservices manage growing com- plexity by functionally decomposing large systems into a set of independent services
  * By making services completely independent in development and deployment, microservices emphasise loose coupling and high cohesion by taking modularity to the next level
  * It also comes with a bundle of problems that are inherited from distributed systems and from SOA, its predecessor. The Mi- croservices architecture still shows distinctive characteristics that blend into something unique and different from SOA itself:
    * Size - The size is comparatively small wrt. a typical service, supporting the belief that the architectural design of a system is highly dependent on the structural design of the organization producing it. Idiomatic use of the microservices architecture suggests that if a service is too large, it should be split into two or more services, thus preserving granularity and maintaining focus on providing only a single business capability. This brings benefits in terms of service maintainability and extendability
    * Bounded context - Related functionalities are combined into a single business capability, which is then implemented as a service.
    * Independency - Each service in microservice architecture is operationally independent from other services and the only form of communication between services is through their pub- lished interfaces
  * The key system characteristics for microservices are: 
    * Flexibility - A system is able to keep up with the ever-changing business environment and is able to support all modifications that is necessary for an organisation to stay competitive on the market
    * Modularity - A system is composed of isolated components where each component con- tributes to the overall system behaviour rather than having a single component that offers full functionality
    * Evolution - A system should stay maintainable while constantly evolving and addingnew features
  * bzgl Teams:
    * Back in 1968, Melvin Conway proposed that an organisation’s structure, or more specifically, its communication structure constrains a system’s design such that the resulting design is a copy of the organisation’s communication patterns [23]. The microservices approach is to organise cross- functional teams around services, which in turn are organised around business capabilities [33]. This approach is also known as “you build, you run it” principle, first introduced by Amazon CTOWerner Vogels [38]. According to this approach, teams are responsible for full support and development of a service throughout its lifecycle
  * Each microservice may represent a single business capability that is delivered and updated in- dependently and on its own schedule
  * Discovering a bug and or adding a minor improvement do not have any impact on other services and on their release schedule (of course, as long as back- wards compatibility is preserved and a service interface remains unchanged)
  * essentially microservices are meant to be used with continuous delivery and continuous integration, making each stage of delivery pipeline automatic. By using automated continuous delivery pipelines and modern container tools, it is possible to deploy an updated version of a service to production in a matter of seconds
  * microservicesmay cooperate in order to providemore complex and elaborate functionalities. There are two approaches to establish this cooperation – orchestration [54] and choreography [69]. Orchestration requires a conductor – a central service that will send requests to other services and oversee the process by receiving responses.Choreography, on the other hand, assumes no centralisation and uses events and publish/subscribemechanisms in order to establish collaboration. These two concepts are not new to microservices, but rather are inherited from the SOA world where languages such asWS-BPEL [66] andWS-CDL [82] have long represented the major references for orchestration and choreography respectively (with vivid discussions between the two communities of supporters).
  * Prior to the advent of microservices and at the beginning of the SOA’s hype in particular, orchestration was generally more popular and widely adopted, due to its simplicity of use and easier ways to manage complexity. However, it clearly leads to service coupling and uneven distribution of responsibilities, and therefore some services have a more centralising role than others.
  * Microservices’ culture of decentralisation and the high degrees of independence represents instead the natural application scenario for the use of choreography as a means of achieving collaboration. This approach has indeed recently seen a renewed interest in connection with the broader diffusion of microservices in what can be called the second wave of services
  * In order to better grasp microservices we need to understand the impact that this architecture has on some software quality attributes.
    * Availability
      * major concern in microservices as it directly affects the success of a system
      * Given services independence, the whole system availability can be estimated in terms of the availability of the individual services that compose the system
      * Even if a single service is not available to satisfy a request, the whole system may be compromised and experience di- rect consequences
    * Reliability
      * Given the distributed nature of the microservices architecture, particular attention should be paid to the reliability of message-passing mechanisms between services and to the reliability of the services themselves
      * Building the system out of small and simple components is also one of the rules introduced in [72], which states that in order to achieve higher reliability one must find a way to manage the complexities of a large system: 
      * building things out of simple components with clean interfaces is one way to achieve this
      * The greatest threat to microservices reliability lies in the domain of integration and therefore when talking about microservices reli- ability, one should also mention integration mechanisms
      * One example of this assumption being false is using a network as an integration mechanism and assuming network reliability is one of the first fallacies of distributed computing [73]. Therefore, in this aspect, **microservices reliability is inferior to the applications that use in-memory calls**
      * It should be noted that this downside is not unique only to microservices and can be found in any distributed system. When talking about messaging reliability, it is also **useful to remember that microservices put restrictions on integration mechanisms**. More specifically, microservices use integration mechanisms in a very straightforward way - by removing all functionality that is not related to the message delivering and focusing solely on reliable message delivery
    * Maintainability
      * By nature, the microservices architecture is loosely coupled, meaning that there is a small number of links between services and services themselves being independent. This greatly contributes to the maintainability of a system by minimising the costs of modifying ser- vices, fixing errors or adding new functionality
      * Despite all efforts to make a system as maintain- able as possible, it is always possible to spoil maintainability by writing obscure and counterintu- itive code [5]. 
      * As such, another aspect of microservices that can lead to increased maintainability is the above mentioned “you build it, you run it” principle, which leads to better understanding a given service, its business capabilities and roles [29,21].
    * Performance
      * The prominent factor that negatively impacts performance in the microservices architecture is communication over a network
      * The network latency is much greater than that of memory.
      * Therefore, in terms of communication, the performance will degrade compared to applications that use in-memory call mechanisms. Restrictions that microservices put on size also indirectly contribute to this factor. In more general architectures without size-related restrictions, the ratio of in-memory calls to the total number of calls is higher than in the microservices architecture, which results in less communication over the network.Thus, the exact amount of performance degradation will also depend on the system’s interconnectedness. As such, systems with well-bounded contexts will experience less degradation due to looser coupling and fewer messages sent.
      * In any distributed system security becomes a major concern. In this sense, microservices suffer from the same security vulnerabilities as SOA [6].
    * Security
      * As microservices use REST mechanism and XML with JSON as main data-interchange formats, particular attention should be paid to providing security of the data being transferred. This means adding additional overhead to the system in terms of additional encryption functionality. 
      * Microservices promote service reuse, and as such it is natural to assume that some systems will include third-party services. Therefore, an additional challenge is to provide authenticationmechanisms with third-party services and ensure that the sent data is stored securely. 
      * In summary, microservices’ security is impacted in a rather negative manner because one has to consider and implement additional security mechanisms to provide additional security functionality mentioned above
    * Testability
      * Since all components in a microservices architecture are independent, each compo- nent can be tested in isolation, which significantly improves component testability compared to monolithic architecture. It also allows to adjust the scope of testing based on the size of changes. This means that with microservices it is possible to isolate parts of the system that changed and parts that were affected by the change and to test them independently from the rest of the system
      * Integration testing, on the other hand, can become very tricky, especially when the system that is being tested is very large, and there are too many connections between components. It is possible to test each service individually, but anomalies can emerge from collaboration of a number of services
  * in [@Fra17] wird über dieses Paper bebhauptet:
    * one of the main results of the survey is that MSA is intrinsically related and has direct impact on specific quality properties at the system level, specifically: availability, reliability, maintainability, performance, security and testability qualities

* Tomorrow:
  * The greatest strength of microservices comes from pervasive distribution: even the internal components of software are autonomous services, leading to loosely coupled systems and the other benefits previously discussed. However, from this same aspect (distribution) also comes its greatest weakness: programming distributed systems is inherently harder than monoliths.Wenow have to think about new issues.
  * Dependability
    * There are many pitfalls that we need to keep in mind when programming with microservices. In particular, preventing programming errors is hard. Consequently, building dependable systems is challenging.
    * Interfaces Since microservices are autonomous, we are free to use the most appropriate technol-ogy for the development of each microservice. A disadvantage introduced by this practice is that different technologies typically have different means of specifying contracts for the composition of services (e.g., interfaces in Java, orWSDL documents inWeb Services [20]).
    * Unfortunately, the current answer is informal documentation.
    * As an attempt to fix this problem, there are tools for the formal specification of message types for data exchange, which one can use to define service interfaces independently of specific technologies. Then, these technology-agnostic specifications can be either compiled to language-specific interfaces — e.g., compiling an interface to a Java type — or used to check for well-typedness of messages (wrt. interfaces and independently of the transport protocol).
    * However, it is still unclear how to adapt tools to implement the mechanical checking (at compile or execution time) of messages for some widespread architectural styles for microservices, such as REST [30], where interfaces are constrained to a fixed set of operations and actions are expressed on dynamic resource paths.
    * A first attempt at bridging the world of technology-agnostic interfaces based on operations and REST is presented in [61], but checking for the correctness of the binding information between the two is still left as a manual task to the programmer.
    * Behavioural Specifications and Choreographies Having formally-defined interfaces in the form of an API is not enough to guarantee the compatibility of services.
    * This is because, during execution, services may engage in sessions during which they perform message exchanges in a precise order. If two services engage in a session and start performing incompatible I/O, this can lead to various problems. Examples include: a client sending a message on a stream that was previously closed; deadlocks, when two services expect a message from one another without sending anything; or, a client trying to access an operation that is offered by a server only after a successful distributed authentication protocol with a third-party is performed.
    * Behavioural types are types that can describe the behaviour of services and can be used to check that two (or more) services have compatible actions. Session types are a prime example of behavioural types [45,46].
    * Session types have been successfully applied to many contexts already, ranging from parallel to distributed computing.
    * However, no behavioural type theory is widely adopted in practice yet. This is mainly because behavioural types restrict the kind of behaviours that programmers can write for services, limiting their applicability. An important example of a feature with space for improvement is non-determinism. In many interesting protocols, like those for distributed agreement, execution is non-deterministic and depending on what happens at runtime, the participants have to react differently
    * Behavioural interfaces are a hot topic right now and will likely play an important role in the future of microservices. We envision that they will also be useful for the development of automatic testing frameworks that check the communication behaviour of services.
    * Choreographies are high-level descriptions of the communications that we want to happen in a system in contrast with the typical methodology of defining the behaviour of each service separately.
    * Choreographies are used in some models for behavioural interfaces, but they actually originate from efforts at the W3C of defining a language that describes the global behaviour of service systems [40].
    * In Chore-ographic Programming, the programmer uses choreographies to program service systems and then a compiler is used to automatically generate compliant implementations. This yields a correctness-by-construction methodology, guaranteeing important properties such as deadlock-freedom and lack of communication errors [15,17,63].
    * A recent line of work suggests that a positive answer can be found by connecting behavioural types and choreographies to well-known logical models. A prominent example is a Curry-Howard correspondence between session types and the process model of π-calculus, given in [14] (linear logical propositions correspond to session types, and communications to proof normalization in linear logic). This result has propelled many other results, among which: a logical reconstruc-tion of behavioural types in classical linear logic that supports parametric polymorphism [83]; type theories for integrating higher-order process models with functional computation [79]; ini-tial ideas for algorithms for extracting choreographies from separate service programs [18]; a logical characterisation of choreography-based behavioural types [19]; and, explanations of how interactions among multiple services (multiparty sessions) are related to well-known techniques for logical reasoning [16,13].
    * We can then conclude that formal methods based on well-known techniques seem to be a promising starting point for tackling the issue of writing correct microservice systems. This starting point gives us solid footing for exploring the more focused disciplines that we will need in the future, addressing problems like the description of coordination patterns among services. We envision that these patterns will benefit from the rich set of features that formal languages and process models have to offer, such as expressive type theories and logics. It is still unclear, however, how exactly these disciplines can be extended to naturally capture the practical sce-narios that we encounter in microservices.We believe that empirically investigating microservice programming will be beneficial in finding precise research directions in this regard.
  * Trust and Security
    * *Greater Surface Attack Area*: In monolithic architectures, application processes communicate via internal data structures or internal communication (for instance, socket or RMI). The attack surface is usually also constrained to a single OS. On the contrary, the microservices paradigm is characterised by applications that are broken down into services that interact with each other through APIs exposed to the network. APIs are independent of machine architectures and even programming languages. As a result, they are exposed to more potential attacks than traditional subroutines or functionalities of a large application, which only interacted with other parts of the same application.Moreover, application internals (the microservices) have now become accessible from the external world. Rephrasing, this means that microservices can in principle send the attack surface of a given application through the roof.
    * Network Complexity
    * Trust
    * Heterogeneity
    * *Heterogeneity*: The microservices paradigm brings heterogeneity (of distributed systems) to itsmaximum expression. Indeed, a microservices-based system can be characterised by: a large num-ber of autonomous entities that are not necessarily known in advance (again, trust issue); a large number of different administrative security domains, creating competition amongst providers of different services; a large number of interactions across different domains (through APIs); no common security infrastructure (different “Trusted Computing Base); and last but not least, no global system to enforce rules.
* A specific arc has been given to the narrative, which necessarily emphasises some connections and some literature, and it is possibly too severe with other sources. For example, research contributions in the domain of the actor model [43] and software agents [65] have not been emphasised enough,

# [@Erb12] Concurrent Programming for Scalable Web Architectures

* 2.3.5 Concurrency, Programming Languages and Distributed Systems
  * we consider the strong relationship between concurrent programming, programming languages and distributed systems when building large architectures. Programming distributed systems introduces a set of additional challenges compared to regular programming. The “Fallacies of Distributed Computing” [RGO06] provide a good overview on some of the important pitfalls thatmust be addressed.
  * From a soſtware engineering perspective, themajor challenges are fault tolerance, integration of distribution aspects and reliability. As we have already seen before, distributed systems are inherently concurrent and parallel, thus concurrency control is also essential.
  * Programming languages to be used for distributed systemsmust either incorporate appropriate language idioms and features tomeet these requirements. Otherwise, frameworks are necessary to provide additional features on top of the core language.
  * Ghosh et al. [Gho11] have considered the impact of programming languages on distributed systems. They pointed out thatmainstreamlanguages like Java and C++ are still themost popular choice of developing distributed systems. They are combined with middleware frameworksmost of the time, providing additional features. However, the strengths of general purpose languages do not cover themain requirements of distributed systems to a great extent.
  * The experiences with RPC-based systems (see Kendall et al. [Ken94]) and their object-based descendents (see Vinoski [Vin08]) have raised some questions to this approach.Middleware systems providing distributability compensate for features missing at the core of a language. Thus, the systems actuallymeet thenecessary requirements, but they are oſten also cumbersome touse and introduce superfluous complexity.
  * Recently, there has been an increasing interest in various alternative programming languages embracing high-level concurrency and distributed computing. Being less general, these languages focus on important concepts and idioms for distributed systems, such as component abstractions, fault tolerance and distributionmechanisms. It is interesting for our considerations thatmost of these languages oriented towards distributed computing also incorporate alternative concurrency approaches.We will have a brief look on some of these languages as part of chapter 5.
* 2.4.3 Scalability and Concurrency
  * The relation between scalability and concurrency is twofold. Fromone perspective, concurrency is a feature that can make an application scalable. Increasing load is opposed to increasing concurrency and parallelism inside the application. Thanks to concurrency, the application stays operational and utilizes the underlying hardware to its full extent. That is, above all, scaling the execution of the application amongmultiple available CPUs/cores. Although it is important to differentiate between increased performance and scalability, we can apply some rules to point out the positive impacts of parallelism for scalability. Certain problems can be solved faster when more resources are available. By speeding up tasks, we are able to conductmore work at the same time. This is especially effective when the work is composed of small, independent tasks.
  * We will now have a look at a basic law that describes the speed-up of parallel executions. Amdahl’s law [Goe06], as seen in equation 2.1, describes themaximum improvement of a system to expect when resources are added to a system under the assumption of parallel execution. A key point hereof is the ratio of serial and parallel subtasks. N is the number of processors (or cores) available, and F denotes the fraction of calculations to be executed serially.
  * From a different angle, concurrency mechanisms themselves have some kind of scalability property. That is basically the ability to support increasing numbers of concurrent activities or flows of execution inside the concurrencymodel. In practice, this involves the language idioms representing flows of executions and correspondingmappings to underlying concepts such as threads.
* 5.2.1 The Implications of Shared and Mutable State
  * Conceptually, a thread describes a sequential flow of control, that is isolated fromother activities at first glance. Unlike processes, threads share the same address space though. That implies that multiple independent threadsmay access the same variables and states concurrently. Even worse, sequential programming is built on the concept of mutable state, which means that multiple threadsmay compete forwrite operations, too.Multithreading is principally usedwith preemptive scheduling. As a result, the exact switches and interleavings betweenmultiple threads are not known in advance. This represents a strong formof indeterminacy.Without further care,mutable state and indeterminacy introduce the strong hazard of race conditions.
  * A race condition occurs when two or more thread compete for access to critical section, a section that contains state shared between threads. Due to the variety of possible interleavings, the race condition may result in various inconsistent states. For instance, a thread may read stale state while another thread is already updating it.Whenmultiple threads alter the state at the same time, either one of the changesmay last and the others get lost, or even a inconsistent state affected bymultiple changesmay persist. Eventually, we needmechanisms to guard critical sections and enforce synchronized access.
* 5.3.3 The Transactional Memory / Garbage Collection Analogy
  * Last but not least, the continuing success of Clojure1 testify thematurity of newer STMimplementations. Clojure is the first programming language that has a STMas first-class, built-in concurrency concept. Prior to Clojure, STMimplementations were mainly found as extensions to ConcurrentHaskell, based on special monads.
  * Probably themost interesting notion in this argument around TMis the analogy to garbage collection [Gro07]. While garbage collection addresses managed references, TM addresses managed state. Both concepts operate on the memory at runtime and take difficult work out of the hands of application developers.
* 9.2.3 New Takes on Concurrency and Distributed Programming
  * Distributed Dataflow Programming
    * Declarative dataflow programming provides a concurrencymodel with inherent coordination, entirely hidden from the developer. Massively parallel data-centric computing frameworks such asMapReduce [Dea08] have shown the strong points of dataflow programming. However, programming abstractions likeMapReduce heavily constrain the expressiveness compared to pure, non-distributed dataflow languages. Thus, only a small amount of existing algorithms can be applied forMapReduce-based computations. Combining an expressive programmingmodel including dataflow concurrency with a scalable and fault-tolerant distributed execution engine represents a sweet spot for programming in the large.

# [@Fra17] Architecting microservices

  * Fowler and Lewis define the microservice architectural style as an approach for developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanisms, often an HTTP resource API [15].
  * (RQ-1) has revealed that performance and maintainability are among the most investigated quality attributes, while possible research gaps could exist in the field of security, reliability and portability for MSA [13].
  * major barriers to cloud adoption there are security and vendor lock-in and quality assurance.
  * MSA is intrinsically related and has direct impact on specific quality properties at the system level, specifically: availability, reliability, maintainability, performance, security and testabil-ity qualities.
  * Availability and scalability are largely discussed in multiple resources and books [33, 39]
    * 33: S. Newman. Building Microservices.O'Reilly Media, Inc., 2015
    * 39: M. Richards. Microservices vs. service-oriented architecture, 2015
  * Hassan and Bahsoon in a recent study [19] have addressed some design problems about estimating the proper level of granularity of services. More specifically, they considered the existing trade offs between the following design concerns: size versus the number of services, and local versus global satisfac-tion of quality properties.
  * In conclusion, in the state of the art of MSA, many quality properties (with their trade offs), design tactics, and architectural analysis and reasoning techniques must still be investigated and explored in order to identify and take full advantage of the potential benefits that MSA can offer.
  * The state of the art does not seem to currently offer a ar- chitectural language for specifically describing and designing microservice architectures. The most promising languages for MSA are the ALs used to describe service-based architectures. Among the most relevant we have identified the following SoaML, SOMA, SOADL and StratusML
  * SOAML is an UML profile for modeling services on business and system levels, service contracts and interfaces, choreography, and more. SoaML metamodel extends the UML2 metamodel to support an explicit service modeling in distributed environments and can be used by most of UML tools.

# [@Giv14] Object-Oriented Parallel Programming

* [based on the observation that programming objects can be naturally interpreted as processes]{.important}.
* that communicate by executing remote methods
* Programming objects can be thought of as processes
* the above program differs from the standard C++ only in the extension of the operator new.
* new allocates objects on remote machines, using the address of the remote machine specified inside parentheses.
* The construction of a new object on a remote machine creates a new process on that machine.
* The introduction of processes, accessible by remote pointers, creates an object-oriented framework for parallel program- ming. Processes exchange information by executing meth- ods on remote objects rather than by passing messages.
* Having defined processes as programming objects, it is now straightforward to derive new processes using previously defined processes. We illustrate process inheritance by extend- ing the example of the previous section.
* In this paper we have shown that programming objects have a natural interpretation as processes

# [@Gue99] From Active Objects to Autonomous Agents

* p.68: Combining the agent concept and the object paradigm leads to the notion of agent-oriented program-ming -- Highlighted 21 May 2017
* p.68: The concept of an active object—integrating an object and activity (namely a thread or process)—provides some degree of autonomy in that it does not rely on external resources for activation -- Highlighted 21 May 2017
* p.68: Carl Hewitt introduced the active-object (or actor) concept to describe a set of entities that cooperate and communicate through message passing. This concept brings the benefits of object orientation (for example, modularity and encapsulation) to distributed environments and provides object-oriented languages with some of the characteristics of open systems -- Highlighted 21 May 2017
* p.69: Active objects are monolithic and have procedural behavior. -- Highlighted 21 May 2017
* p.69: An agent is not monolithic. -- Highlighted 21 May 2017
* p.70: It can have several behaviors: communication, perception, deliberation, and so forth -- Highlighted 21 May 2017
* p.70: An agent has a goal; it does not simply act in response to messages from other agents -- Highlighted 21 May 2017

# [@Has16] Microservices and Their Design Trade-offs: A Self-Adaptive Roadmap

  * Abstract—Migrating to microservices (microservitization) en-ables optimising the autonomy, replaceability, decentralised governance and traceability of software architectures.
  * Despite the hype for microservitization , the state of the art still lacks consensus on the definition of microservices, their properties and their modelling techniques.
  * One such design problem is finalising the optimal level of granularity of a microservice architecture. Related design trade-offs include: balancing the size and number of microservices in an architecture and balancing the non-functional requirement satisfaction levels of the individual microservices as well as their satisfaction for the overall system.
  * We therefore view microservitizationas a form of servitization where services/components are transform into microservices —- a more fine-grained and autonomic form of services —- to add long-term value to the architecture.
  * Isolating business functionalities aims at optimis-ing the autonomy and replaceability of the service(s).
  * Despite the hype and the business push towards mi-croservitization [1], there is a lack of academic consensus regarding the definition and properties of the paradigm shift and corresponding design patterns for microservices [4].
  * Among these problems is finalising the level of granularity of a microservice too early. "Splitting too soon can make things very difficult to reason about. It will likely happen that you (the software architect) will learn in the process. [1]."
  * the size versus number of microservices [4]
  * the local versus global non-fuctional requirement satisfaction trade-off.
  * aggressive isolation of business functionalities is not necessarily ideal for all scenarios of the environment.
  * Due to the recency of the research area, there is a multitude of ways in which microservices have been defined and modelled. Clear understanding of the paradigm shift, itsmotivations, and implications are prerequisites for advancing microservitization. We have reviewed the state of art and practice to capture the different ways in which microservices can be defined and modelled.
  * We therefore view microservices as autonomic, repleace-able and deployable artefacts of microservitization that encapsulate fine-grained business functionalities presented to system users through standardised interfaces. The autonomy of these artefacts allows for governing them in a decentralised manner and tracing their changes.
  * Among the crucial and non-trivial decision problems (DPs) that constitute addressing the size/number and the local/global NFRs satisfaction trade-offs are the following:
    * When does decomposing a microservice into more fine-grained ones achieve the required optimality for both trade-offs?
    * When does merging several fine-grained microser-vices into a coarse-grained one achieve the required optimality for both trade-offs?
    * When should the current level of granularity be kept without further merging or decomposition?

# [@Lav95] Active Object -- An Object Behavioral Pattern for Concurrent Programming

* The ActiveObject pattern decouples method execution from method invocation in order to simplify synchronized access to a shared resource bymethods invoked in different threads of control
* To illustrate the Active Object pattern, consider the design of a connection-oriented Gateway. A Gateway decouples cooperating components in a distributed system and allows them to interact without having direct dependencies among each other
* This pattern enables a method to execute in a different thread than the one that invoked the method originally. In contrast, passive objects execute in the same thread as the object that called a method on the passiv object.
* The active object Gateway design resolves the following forces:
  * Simplify flow control
  * Simplifyconcurrent programming
  * Take advantage of parallelism
* Use the Active Object pattern when
  * The design and implementation of a concurrent program can be simplified
  * Multiple threads of control require synchronized access to shared data
  * The order of method execution can differ from the order of method invocation
  * The operations on a shared object are relatively coarse-grained
* The Active Object pattern offers the following benefit
  * Enhance application concurrency while reducing synchronization complexity
  * Leverage parallelism available from the hardware and software platform
* The Active Object pattern has the following drawbacks
  * It potentially increases context switching, data movement, and synchronization overhead
  * It may be difficult to debug programs containing active objects due to the concurrency and non-determinism of the Scheduler

# [@Maz16] Towards Microservices and Beyond: An incoming Paradigm Shift in Distributed Computing

* Object-oriented technologies are prominent in software development
* A notable example is the Eiffel programming language [9], incorporating solid principles of OOP within a programming framework coordinated by the idea of design- by-contract, which aims at correctness-by-construction.
* Component-wise each build- ing block is built as a microservice [11] embedding busi- ness capabilities in isolation. Every microservice can be reused, orchestrated, and aggregated with others [10]
* The microservices architecture [4] is built on very simple principles:
  - Bounded Context. First introduced in [5], this con- cept captures one of the key properties of microservice architecture: focus on business capabilities. Related functionalities are combined into a single business ca- pability which is then implemented as a service.
  - Size; benefits in terms of service maintainability and extendability; Idiomatic use of microservices architecture suggests that if a service is too large, it should be refined into two or more services, thus pre-serving granularity andmaintaining focus on providing only a single business capability.
  - Independency: concepts encourages loose cou- pling and high cohesion by stating that each service Independency. This concepts encourages loose cou- pling and high cohesion by stating that each service in microservice architectures is operationally indepen-dent from others, and the only form of communication between services is through their published interfaces.
* Even though it is likely to conduct to a paradigm shift and a dramatic change in perception, it does not build on vacuum, and instead relates to well-established paradigms such as OO and SOA.
* [...] focusing on the evolutionary aspects more than the revolutionary ones.

# [@Mon16a] Circuit Breakers, Discovery, and API Gateways in Microservices

  * components of an application are autonnomous services that execute independently
  * communicate via message passing
  * message passing introduces the possiilities of communnication failures and timeouts among components
    * vgl.: im Actor Model ist die Zustellung von Nachrichten garantiert
  * inspired by SOA
  * key difference between SOA and MS lies in granularity (in SOA, all services are parts of a monolith)
  * components can e deployed separately
  * new versions can be gradually introduced into a system  
    * vgl. Subtyping Idee
  * Components can be more specialized, since they can be written in different techologies
  * services may become overloaded (too many concurrent client requests) or resources kept busy
  * this may easily trigger disastrous cascading failures
  * failure in an MSA is inevitale and should embraced with precaution rather than ignored
  * Failing service may have other services depending on it (what if it becomes unresponsive?)
    * -> circuit breaker pattern; fail fast
    * mit Circuit Breaker State Diagram p.2 !
  * Circuit Breaker: 
    * Hysterix Library
    * Server-side Circuit Breaker
    * Client-side Circuit Breaker
    * Proxy Circuit Breaker
      * introduces Network bottle neck
  * Service Discovery
    * Location of MS may not be statically known at design time
    * using Service registry
      * adopted from SOA
      * = a service that can be used y other components to retrieve ending information about other components
      * in SOA, service discovery part of enterprise service bus
      * in MSA, service discovery as non-standard custom implementations
    * Gateways:
      * single entry point for many APIs
      * since it is an entry point, it is natural to equip it with e.g. service discovery load-balancing, monitoring, security, etc
  * "being essentially distributed, microservices is founded on the well-known mechanism of message passing"
  * all internal services are subjects to potential communciation failures and overloads
  * choreography does not require central control. a critical feature for the scalability of MSA

alternativ habe ich bereits vorher einmal markiert scheinbar:

* p.1:  Jolie, a language -- Highlighted 19 May 2017
* p.1: inspired by Service-Oriented Architecture (SOA). The key difference between the two approaches lies in granularity. -- Highlighted 19 May 2017
* p.1: a single executable artifact, called a monolith -- Highlighted 19 May 2017
* p.1: Components can be deployed separate, -- Highlighted 19 May 2017
* p.1: New versions of components can be gradually introduced in a system -- Highlighted 19 May 2017
* p.1: Components can be more specialised -- Highlighted 19 May 2017
* p.1: Scaling a microservice architecture does not imply a duplication of all its components -- Highlighted 19 May 2017
* p.1: Interactions among microservices happen via message passing, which introduces the possibilities of communication failures and timeouts among components. -- Highlighted 19 May 2017
* p.1: Services may become overloaded, because of too many concurrent client requests or resources being kept busy while waiting for replies from other services. This may easily trigger disastrous cascading failures. -- Highlighted 19 May 2017
* p.1: Microservices can use different technologies, enabling specialisation to specific clients and tasks. -- Highlighted 19 May 2017
* p.2: We also demonstrate how the solutions that carry novelty in the setting of microservices can be prototyped using constructs developed for service composition in Jolie [26], a native microservice programming language [20]. -- Highlighted 19 May 2017
* p.2: Failure in an MSA is inevitable, and should be embraced with precaution rather than ignored. -- Highlighted 19 May 2017
* p.2: The motto here is to fail fast: when a service becomes unresponsive, its invokers should stop waiting for it, assume the worst, and start dealing with the fact that the failing service may be unavailable -- Highlighted 19 May 2017
* p.2: One of the most famous implementations of circuit breakers is provided by the Hystrix library [30] -- Highlighted 19 May 2017
* p.2: Here, we make the (novel) observation that it makes sense to deploy a circuit breaker also in other places than just inside of clients -- Highlighted 19 May 2017
* p.5: In practice, the location of a microservice may not be statically known at design time. -- Highlighted 19 May 2017
* p.5: A service registry is a service that can be used by other components to retrieve binding information about other components -- Highlighted 19 May 2017
* p.6: An MSA may need to serve different kinds of clients and user interfaces, such as those found in web browsers and various smart devices  -- Highlighted 19 May 2017
* p.6: depending on the quality of its current network connection, a device may want to use an API that is more or less network intensive -- Highlighted 19 May 2017
* p.6: It is a single entry point that provides access to many APIs -- Highlighted 19 May 2017
* p.6: Since an API Gateway is an entry point for the MSA, it is natural to equip it with, e.g., service discovery, load balancing, monitoring, and security. -- Highlighted 19 May 2017
* p.6: Since an API Gateway is an entry point for the MSA, it is natural to equip it with, e.g., service discovery, load balancing, monitoring, and security.Its position in the system is also ideal for adopting the proxy circuit breaker pattern, by equipping the API Gateway with circuit breakers for clients and/or services -- Highlighted 19 May 2017
* p.7: However, MSAs are much more involved than other distributed applications where services are implemented as monoliths, because all internal components are subjects to potential communication failures and overloads -- Highlighted 19 May 2017
* p.7: Circuit breakers have first been popularised in [35], where their role is discussed in the context of availability (resilience) for enterprise systems -- Highlighted 19 May 2017
* p.7: Akka [22] provides a circuit breaker implementation that supports basic configuration parameters, such as call timeout, failure threshold and reset threshold. Hystrix [30] is much more flexible and is currently one of the reference solutions: -- Highlighted 19 May 2017

# [@OBr05] Quality Attributes and Service-Oriented Architectures

  * Software architecture is the bridge between mission/business goals and a software-intensive system.
  * In this report, we use the term service-oriented architecture to mean an architectural approach for building systems or applications that use a set of services and not just a system that is built as a set of services.
  * A service is an implementation of a well-defined piece of business functionality, with a published interface that is discoverable and can be used by service consumers when building different applications and business processes.
  * There is no single, official definition of what an SOA is. Consequently, many of the organizations promoting the use of SOAs and building technologies to make it easier for organizations to adopt an SOA approach have defined the term. As a result, SOA is defined in many different ways, including
    * "A service-oriented architecture (SOA) is an application framework that takes everyday business applications and breaks them down into individual business functions and processes, called services. An SOA lets you build, deploy and integrate these services independent of applications and the computing platforms on which they run." -- IBM Corporation
    * "Service-Oriented Architecture is an approach to organizing information technology in which data, logic, and infrastructure resources are accessed by routing messages between network interfaces." -- Microsoft
    * An SOA is "a set of components which can be invoked, and whose interface descriptions can be published and discovered." -- Worldwide Web Consortium [W3C 04]
  * Just as there is no official definition of SOA, there is no official set of service-orientation design principles. There are, however, a common set of service-level design principles most associated with service orientation [Erl 05, McGovern 03]:
    * Services are reusable. Regardless of whether immediate reuse opportunities exist, services are designed to support potential reuse
    * Services share a formal contract. In order for them to interact, they need not share anything but a formal contract that defines the terms of information exchange and any supplemental service description information
    * Services are loosely coupled. They must be designed to interact on a loosely coupled basis, and they must maintain this state of loose coupling
    * Services abstract underlying logic. The only part of a service that is visible to the outside world is what is exposed via the service’s description and formal contract. The underlying logic (beyond what is expressed in the description and formal contract) is invisible and irrelevant to service requestors
    * Services are composable. They may compose other services. This possibility allows logic to be represented at different levels of granularity and promotes reusability and the creation of abstraction layers
    * Services are autonomous. The logic governed by a service resides within an explicit boundary. The service has complete autonomy within this boundary and is not dependent on other services for the execution of this governance
    * Services are stateless. They should not be required to manage state information, since that can impede their ability to remain loosely coupled. Services should be designed to maximize statelessness even if that means deferring state management elsewhere
    * Services are discoverable. They should allow their descriptions to be discovered and understood by humans and service users who may be able to make use of the services’ logic. Service discovery can be facilitated by the use of a directory provider, or, if the address of the service is known during implementation, the address can be hard-coded into the user’s software during implementation
    * Services have a network-addressable interface. Service requestors must be able to invoke a service across the network. When a service user and service provider are on the same machine, it may be possible to access the service through a local interface and not through the network. However, the service must also support remote requests
    * Services are location transparent. Service requestors do not have to access a service using its absolute network address. Requestors dynamically discover the location of a service looking up a registry. This feature allows services to move from one location to another without affecting the requestors.
  * Of the principles described above, autonomy, loose coupling, abstraction, and the need for a formal contract can be considered the core principles that form the baseline foundation for SOA
  * Furthermore, an application is created by assembling and coordinating the activities between the appropriate services it needs to accomplish its business process
  * With an SOA, if the business rules associated with a specific function change, developers must modify only the one service that implements the function. In theory, all applications that use the service will then automatically adopt the new business rules
  * It is critically important to identify what piece of functionality will become services and to define the interfaces of those services. The granularity of the service (i.e., the scope of functionality a service exposes) is also important because having many fine-grained services may result in a lot of message passing between the service users and the service providers. Coarse-grained services are recommended, which, like any other large pieces of software, may need to be architected themselves.
  * Wilkes and Veryard outline a set of principles for architecting and designing an SOA that impacts agility [Wilkes 04]. These principles include some of those outlined earlier—such as loose coupling and precise specification of services—and additional ones such as standardized services, standards compliance, and defining services as coarse-grained.
  * SOAs and Quality Attributes
    * Interoperability
      * Interoperability refers to the ability of a collection of communicating entities to share specific information and operate on it according to an agreed-upon operational semantics [Brownsword 04]. 
      * Increased interoperability is the most prominent benefit of SOA, especially when we consider Web services technology [McGovern 03]. 
      * Distributed systems have been developed using various languages and platforms that vary from portable devices to mainframes. They have used technologies such as the Common Object Request Broker Architecture (CORBA), Remote Method Invocation (RMI), Distributed Component Object Model (DCOM), Remote Procedure Call (RPC), and sockets for communication. However, until the advent of Web services, there was no standard communication protocol or data format that could be used effectively by systems using different technologies to interoperate on a worldwide scale
      * Components implemented in disparate platforms using different languages can interact transparently through a call-and-return mechanism.
    * Reliability
      * Reliability is the ability of a system to keep operating over time [Clements 02].
      * Message Reliability
        * Services are often made available over a network with possibly unreliable communication channels. Connections break and messages fail to get delivered or are delivered more than once or in the wrong sequence
      * Service Reliability
        * Service reliability means the service operates correctly and either does not fail or reports any failure to the service user.
    * Availability
      * Availability is the degree to which a system or component is operational and accessible when required for use.
      * From the services user’s perspective, if the system relies on a set of services being available in order to meet its functional requirements and one of those services becomes unavailable (even transiently), it could have dire consequences on the success of the system. 
      * From the service provider’s perspective, in order for the services to be used (for which the provider may receive compensation), they must be available when needed.
      * Service providers usually agree to provide to the service users a set of services and to include each service in an SLA. The SLA defines the contract for the provision of the service with details such as who provides the service, the guaranteed availability of the service, the escalation process (which is followed if the service is not handled to the service user’s satisfaction), and the penalties to the provider if the service level is not met.
    * Usability
      * Usability is a measure of the quality of a user’s experience in interacting with information or services
      * To provide a more usable system, service providers should consider several things that derive from the distributed and service nature of SOA: data granularity, services to support usability, and disconnected operation.
      * Data granularity: In SOAs, service users and service providers communicate over a network—a process that can introduce delays, possibly on the order of seconds, in user interactions
      * Normal Usability Operations: The service must provide interfaces that support the normal usability operations such as canceling a request, undoing the last request, providing the service on aggregated data, and gaining information for feedback such as percentage completed and time to completion. Bass and John provide a list of possible operations [Bass 03]
    * Security
      * Although security denotes different things with respect to software systems, in general, it is associated with four principles:
        * confidentiality – Access to information/service is granted only to authorized subjects.
        * authenticity – We can trust that the indicated author/sender is the one responsible for the information.
        * integrity – Information is not corrupted
        * availability – The information/service is available in a timely manner.
      * Web services solutions have been addressing some of the security concerns at the network infrastructure level. For example, Web servers that host Web services can be configured to use Secure Sockets Layers (SSLs) and digital certificates to encrypt data transmission and authenticate the communicating parties
      * The architect should be aware of the security features offered by the target Web services platform. Security mechanisms often have a negative impact on performance and modifiability, so the architect may want to investigate these tradeoffs on specific platforms.
    * Performance
      * Like security, performance can have different meanings in different contexts. In general, it is related to response time (how long it takes to process a request), throughput (how many requests overall can be processed per unit of time), or timeliness (ability to meet deadlines, i.e., to process a request in a deterministic and acceptable amount of time).
      * Performance is an important quality attribute that is usually affected negatively in SOAs. Careful design and evaluation of the architecture for the specific solution is necessary to avoid performance pitfalls. The key factors in SOA that contribute to performance issues are
        * SOA involves distributed computing. Service and service user components are normally located in different containers, most often on different machines. The need to communicate over the network increases the response time. Typical networks used for SOA, such as the Internet, do not guarantee deterministic latency
        * The interaction protocol sometimes requires a call to a directory of services to locate the desired service. This extra call increases the total time needed to perform the transaction. One way to reduce the response time and improve throughput is to prevent the call to the directory by having the location of the provider end point hard-coded (or cached after the first lookup) in the service user. However, hard-coding reduces availability, and caching must be reestablished after failure when another replica is found. [Gateways beheben das Problem des Lookup-calls. Sie habe das chachinng eingebaut, und leiten den call direkt weiter]{.mind}
      * The ability to make services on different platforms interoperate seamlessly has a performance cost. Intermediaries are needed to perform data marshalling and handle all communication between a service user and a service provider. Depending on the SOA technology or framework being used, stubs, skeletons, SOAP engines, proxies, and other kinds of elements are in place. All such intermediaries negatively impact performance. [Gateways sind Proxies, die JSON konverter sind data marshalling dinger]{.mind}
      * The use of a standard messaging format increases the time needed to process a request. As an example, the next section describes how the use of XML impacts the performance of Web Services. [JSON genau so]{.mind}
      * On the positive side, SOA provides location transparency.
      * XML in Web Services as a Performance Factor
        * XML is flexible and extensible, making it suitable to represent any data that can be stored in text format.
        * It has internationalization mechanisms to support multilingual documents. XML documents are human readable: that is, they use a text rather than binary format. In addition to data, XML documents may embed metadata describing the structure of the data. Despite all the benefits, the use of XML as the data representation format in Web Services creates additional overhead in the transmission and processing of data.
        * XML messages can be 10 to 20 times larger than the equivalent binary representation, so transmitting them over a network takes longer. Because XML uses a text format, it has to be processed before any operation is performed.
        * XML processing consists of at least three distinct activities, all of which are CPU and memory intensive:
          1. parsing: the translation of XML data into the proper data structures of the component that consumes the XML. Parsing involves a lot of string processing.
          2. validation: a step prior or concomitant to parsing that ensures that the XML document follows a predefined structure. Validation can be more time-consuming than parsing, especially when a reference to a remote Document Type Definition (DTD) or schema has to be resolved. 
          3. transformation: the translation from one XML structure to another or from XML to some other format. Transformation is usually required when integrating services and components that come from different providers. Transformation can be 10 times slower than XML parsing and should be the first target for performance improvement when optimization of Web Services’ performance is the goal.
        * Many techniques and best practices can be applied to minimize the performance costs of transmitting and processing XML documents; for example
          * Use data compression (e.g., Zip format) on the XML document. There is a tradeoff with a loss in interoperability because both end points must be able to compress/decompress the documents using the same algorithm.
          * Use the appropriate parsing model. The Document Object Model (DOM) should be used when elements in the XML document have to be accessed randomly or when the document has to be processed multiple times or modified. Use the Simple Application Programming Interface (API) for XML (SAX) when the elements have to be processed serially and just once. Also, don’t parse the entire document if you can obtain the desired information by reading only part of it.
          * Turn off validation for documents that were generated by an application and are known to be valid. Once a document is validated, it can be converted to its DTD-less or schema-less equivalent. Also, remote DTDs and schemas can be cached locally or embedded into the XML documents to avoid the remote access.
    * Scalability 
      * Scalability is the ability of an SOA to function well (without degradation of other quality attributes) when the system is changed in size or in volume in order to meet users’ needs [W3C 04].
      * Because service users know only about the service’s interface and not its implementation, changing the implementation to be more scalable requires little overhead [McGovern 03]. Options for solving scalability problems include
        * horizontal scalability: distributing the workload across more computers. Doing so may mean adding an additional tier or more service sites. [besonders bei MS beliebt, da einfach viele viele services parallel + gateway als broker]{.mind}
        * vertical scalability. upgrading to more powerful hardware for the service site
    * Extensibility
      * Extensibility is the ease with which the services’ capabilities can be extended without affecting other services or parts of the system.
      * Extensibility for an architecture today (in particular, an SOA) is important because the business environment in which a software system lives is continually changing and evolving. These changes in the environment will mean changes in the software system, service users, and services providers and the messages exchanged among them. Extending an SOA means making changes that include extending
        * the architecture to add additional services. SOAs allow for the easy addition of new services through loose coupling and the use of various Web standards. Services can be created and published by the providers and discovered by service users. Service users must update their application code to incorporate these new services.
        * existing services without changing the interfaces. Because services are loosely coupled, adding new capabilities to them that do not require a change in the service interface can be done without affecting other services. However, an application may require changes if these new capabilities were already incorporated into the application (i.e., the functionality for these capabilities was either included in the application or handled by additional services). Identifying the services’ capabilities when they are first designed and implemented is very important because later, changes may cause problems within the service users’ applications.
        * existing services with changes to interfaces. Adding new capabilities to a service—ones that require changes to the service interface—may have a major impact on the success of an SOA. Usually, an application learns about a service’s interface by reading informatio provided by the directory provider, and the interface may change over time. The service users’ application must be able to handle any changes to the interface.
      * A major obstacle to extensibility is the interface message. If interface messages are notextensible, users and providers will be locked into one particular version of the interface to aservice. Moreover, messages must be written in a format, structure, and vocabularyunderstood by all parties. Limiting the vocabulary and structure of messages is a necessity forany efficient communication. The more restricted a message is, the easier it is to understand,although it comes at the expense of reduced extensibility. Restriction and extensibility aredeeply entwined. Both are needed, and increasing one comes at the expense of reducing the other. Tradeoffs between them are necessary to achieve the right balance.
  * Adaptability
    * Adaptability means the ease with which a system may be changed to fit changed requirements
    * [hier passt der text nicht so richtug gut auf MS]{.mind}
  * Testability
    * Testability is the degree to which a system or service facilitates the establishment of test criteria and the performance of tests to determine whether those criteria have been met [IEEE 90].
    * Testing a system that uses an SOA can be complex for many reasons including
      * Interactions may be required between distributed pieces of the system (i.e., pieces that run on different machines across a network)
      * The organization may not be able to access the services’ source code, so it can’t identify the test cases required to thoroughly test them. This problem occurs when the services are external to the organization that owns the applications.
      * Services may be discovered at runtime, so it may be impossible to predict which service or set of services is actually used by a system until the system is executing. In addition, different services from different providers may be used at various times when the system runs. The services used may be running on different platforms or operating systems and use different middleware technologies. Building repeatable tests and automating the testing process for such a system will be a challenge.
    * If a problem occurs when the system is running, it may be difficult to find the source of the problem. The problem may be
      * within the application
      * within a service that is being used by the application
      * with in the infrastructure that is used by either the application or the service
      * due to the load on the platform where the service executes
      * within the discovery agent that locates the services
  * Auditability
    * Auditability is the quality factor representing the degree to which an application or component keeps sufficiently adequate records to support one or more specified financial or legal audits.
    * [für MS wurscht würd ich sagen]{.mind}
  * Operability and Deployability
  * Modifiability
    * Modifiability is the ability to make changes to a system quickly and cost-effectively [Clements 02]. [sehr wichtig für MS an sich]{.mind}
    * SOA promotes loose coupling between service consumers and providers. Services are self-contained, modular, and accessed via cohesive interfaces. These characteristics contribute to the creation of loosely coupled SOAs where there are few, well-known dependencies between services. That fact tends to reduce the cost of modifying the implementation of services, hence increasing the system’s modifiability.

# [@Pet16] OrcO: A Concurrency-First Approach to Objects

* The Orc programming language [15, 22] enables a concur- rency-first style of programming, in which programmers start with a concurrent program, instead of adding concurrency only when it is required.
* For instance, in pure active object systems concurrency can only exist between ob- jects so a new object must be introduced to add concurrency even if that object will be adversely coupled to other objects.
* OrcO objects are designed to be orthogonal to concurrency, allowing the concurrent structure and the object structure of a program to evolve independently.
* Orc is pervasively concurrent, because it replaces conventional sequential control structures with concurrency combinators.
* object boundaries are not used to structure concurrency and con- currency within objects is the same as concurrency among objects.
* One example of a superposed computation is logging in a web server. For each request, the server instantiates a Handler and calls its handle method
* ProActive and Asynchronous Sequential Processes provide transparent futures
* Emerald [4, 5], like OrcO, enables concurrency both be- tween and within objects. Like many active object languages, all concurrency in Emerald is provided by a single sequential process attached to each object.
* The parallel actor monitor is allowed to dispatch messages to execute concurrently with other messages in the same actor.
* Oz [35] provides concur- rent object-oriented programming in a constraint logic pro- gramming language. All variables in Oz—including fields— are logic variables and assignment is bidirectional unification.

# [@Ray03] The Art of UNIX Programming

* Chapter 1: "Rule of Composition: Design programs to be connected with other programs; siehe http://homepage.cs.uri.edu/~thenry/resources/unix_art/ch01s06.html#id2877684

# [@Sha17a] Microservices: Granularity vs. Performance

  * Service Oriented Architecture (SOA, and subsequently ""web services"[3, 6]), is a natural fit for "everything-as-a-service", but it is also practical to decompose software applications into discrete services as it can help bridge the comprehension gap between users requirements and design specifications, whilst also improving software design by moving away from more inflexible, monolithic architectures[14, 25].
  * As service orientation thinking matures, there is now the con-struct of Microservice Architecures (MSA)[20], which have gained popularity with software development teams who have a need to be able to provide applications that can scale in response to emerging requirements[23].
  * Microservices can be declared with varying levels of capability, and the size of this functionality is typically referred to as its granularity, that is, the functional complexity coded in a service or number of use cases implemented by a microservice[21].
  * Since microservices are discrete and must be composed into greater functional entities to support businessworkflows, it follows that message passing between microservices (as a result of method invocation) increases as the microservices become finer-grained
  * The 'building-block' approach to service composition is attrac-tive from an architectural perspective; arguments for service re-use can be made, and the gap between application design and the user requirements documentation can be reduced. However, the increase in communication between services (manifesting as out-of-process calls and the number of service calls made) also increases the response time of an application, particularly when many small increases in latency are compounded together[26].
  * Achieving an optimum level of granularity is therefore of interest to application developers who want to exploreMSAfor deployment, and the key factors that contribute to this can be summarised as follows:
    * Driven by business need or capability. The needs of a business may be changing rapidly and demanding new functionality from an application. This growth may not be manageable within the existing application architecture and therefore a granular approach is adopted. It is typical for application developers to use the functionality itself to set the scope that determines the size of a microservice.
    * Size of application. For smaller applications the level of gran- ularity could be fine-grained. For enterprise (larger) sized applications, the granularity is likely to be at a higher level (coarser) with each microservice built up from smaller mi- croservices. However, aswe discuss later, for smaller applica- tions there may stiil need to be an aggregation of services to facilitate simpler communication and reduced latency over IoT network connections
    * Size of development team. Thenumber of developers in a team, together with their skills capability should be considered. Size of development team. Thenumber of developers in a team, together with their skills capability should be considered. Conway(http://www.melconway.com/Home/Conways_Law. html) says “organizations which design systems ... are con-strained to produce designs which are copies of the commu-nication structures of these organizations”. In the context of MSA, but more specifically Domain Driven Design [12], the degree of success of functional decomposition, and its subse-quent implementation as a successful service, is dependent upon the organisational structure of the development teams.
    * Database design. The design of a database may have an im- pact on granularity. For example, in a retail scenario if there Database design. The design of a database may have an im- pact on granularity. For example, in a retail scenario if there is a product service and an order service, the functional de-composition is likely to have led to the implementation of separate data repositories for each service. Any association of the data between the databases will be implemented at code level, leading to more coarse-grained microservices.
    *  Reuse. MSA promotion of reuse in the architecture is a con- cern for enterprise applications. If the services are fine-Reuse. MSA promotion of reuse in the architecture is a con- cern for enterprise applications. If the services are fine-grained then reuse is possible but there is the additional overhead of wiring the services together. If the services are too coarse grained then it is difficult to reuse the services.
    * It follows that whilst architectural concerns may lead designers towards finer-grained functional decomposition[12, 13], any po-tential increase in the number of methods invoked, either within a container or between physical servers via a network, will have an increased contribution towards latency, particularly when virtu-alised. 
    * Containers are one means of addressing the latency to some extent when the microservices exist in cloud environments[9, 19]. 
    * Figure1 illustrates the message request and response between two microservices, A and B. The overall latency is determined by a number of factors, including the following:
      * Number of calls
      * Network latency and availability
      * Availability of microservice
      * Processing time
      * Variability in demand/load
    * While considering latency there are two other factors to consider. First, the criticality of the service being called and second,the number of times it is called. For example, although calling a “qualifi-cation mapping” service is important, it is not critical to the function of the system. If it is not working the system can still accept new applications. 
    * An additional factor to be considered is whether the application under consideration is a new application or an existing application that is being migrated to MSA. For a new application, databasedesign will have less influence as there will not be a database in place already. For an existing application, the organisation and design of existing data and their structures is an important factor to consider.
    * Finer-grained microservices result in a potential increase in the number of in-process method invocations. This is tolerable when the microservices lie within the same container, as the message passing is rapid and the probability that the service request is completed is high and wholly dependent upon the application in the container.
    * Once the messages broach the boundaries of containers to make requests to external microservices, additional vulnerabilities threaten the successful completion of the request, not least the variables introduced by a network connection.
    * As such, the issue of performance is not wholly restricted by latency through increased network traffic, but it is also influenced by additional risks from external communication mechanisms.

# [@Sny93] The Essence of Objects: Concepts and Terms

* New Objects can be created : vgl mit µS, hier können auch neue Services erzeugt werden, um zu skalieren (wenn entsprechend implementiert, daher im allgemeinen schwerer!)
* Active Objects "can initiate computation spontaneously, without being requested to do so by a client, AO is a concurrent process" --> in etwa so wie µS
* Objects can share implementations : wenn mehrere µS von der selben Codebase gestartet werden, tun sie das auch, haben eigenen State, aber "identical state format"
* Objects can share partial implementation : inheritence eher schwierig, aber delegation in µS ganz normal, so auch bei Objekten
* Dynamic Binding : nur eine Idee, aber kann man da einen Vergleich zu API Gateways ziehen, die zur Laufzeit den tatsächlichen Service an den weitergereicht wird (oder das dann selber entsprechende Antwort bei nicht existenz produziert) ziehen?

# [@Vin07] Concurrency with Erlang

* p.1: It’s not an exaggeration to say that writing correct multithreaded programs is beyond many programmers’ technical abilities. -- Highlighted 18 May 2017
* p.1: One of the primary reasons concurrency is so hard is that popular imperative programming languages such as Java and C++ essentially require state to be shared among threads. -- Highlighted 18 May 2017
* p.1: Programmers writing multithreaded applica  tions in languages like Java and C++ spend much   of their time determining what state is shared   among threads and how best to protect its integri  ty within the running application. Finding all the   shared state isn’t always easy.  -- Highlighted 18 May 2017
* p.1: Assuming the pro  grammer can even find it, he or she must then pos  sess the skills, experience, and patience necessary   to determine the best way to serialize access to it -- Highlighted 18 May 2017
* p.1: If locking is too coarse-grained, the application tends toward single-threading -- Highlighted 18 May 2017
* p.1: Such applications make poor use of multicore CPUs and tend to be slow. If locking is too fine-grained, on the other hand, the chances for deadlock increase greatly as different threads are increasingly likely to obtain locks in different orders -- Highlighted 18 May 2017
* p.1:  Idioms, patterns, and frameworks can help out partially, but they introduce restrictions and trade-offs of their own. -- Highlighted 18 May 2017
* p.1: One way to avoid the problems with shared state is to simply avoid it, but that’s impractical in a language like C++ or Java. Doing so requires a combination of libraries or frameworks such as those based on actor models and message passing -- Highlighted 18 May 2017
* p.1: A better way to avoid shared state is to switch to a programming language specifically designed to do exactly that. Erlang is one such language. -- Highlighted 18 May 2017
* p.2: They required their language to help them build highly concurrent, fault-tolerant, highly available, and distributed services that supported live upgrades and ran with virtually zero downtime. -- Highlighted 18 May 2017
* p.2: In fact, it’s so hard that even if you’ve done it before, you can still very easily get it wrong. Consequently, when building a new system, most developers tend to focus first on the nonreplicated, nonreliable version, seriously considering the really hard failover and load-balancing parts only after they get that working. -- Highlighted 18 May 2017
* p.2: Erlang is a functional language that wholly embraces the “shared nothing” concept -- Highlighted 18 May 2017
* p.2: Because Erlang variables are immutable, they don’t need concurrency protection -- Highlighted 18 May 2017
* p.2: Avoiding shared variables allows for higher degrees of program parallelization, assuming threads aren’t too heavyweight. Erlang “processes,” which are essentially user-space threads rather than Unix processes or kernel threads, communicate only via message passing -- Highlighted 18 May 2017
* p.4: Locks, condition variables, and other traditional multithreading constructs simply aren't necessary in any of this code. -- Highlighted 18 May 2017

# [@Xu16] CAOPLE: A Programming Language for Microservices SaaS

* developing applications in the microservices architecture presents three main challenges: 
  * (a) how to program systems that consists of a large number of services running in paral-lel and distributed over a cluster of computers; 
  * (b) how to reduce the communication overhead caused by executing a large number of small services; 
  * (c) how to support the flexi-ble deployment of services to a network to achieve system load balance.
* Such an application runs in a few processes of coarse granularity. Each process implements a large block of functionality, such as receiving service requests, executing some business logic, retrieving and updating data from a database, and sending out response messages.
* One of the main barriers to the development of service oriented applications is the scalability problem. Among many dimensions of scalability, horizontal scaling plays a crucial role in cloud computing, which means replicating multiple identical copies of the processes of the application behind a load balancer
* When a system grows in scale and complexity, making changes to an appli-cation in a monolithic architecture become problematic for programmers and customers, because redeploying a new version means to restart the server, which will take a long time.
* Lewis and Fowler defined MS as an architectural style in which a single application consists of “a suite of small services, each running in its own process and communicating with lightweight mechanisms”. These services are “independently deployable by fully automated deployment machinery” [1].
* MS address the above barriers by decomposing a system into a large number of fine-grained services that are con-nected together through a communication mechanism and supported by a deployment mechanism for replicating and relocating MS in a cluster of servers. One MS’s collapse or going off line will be less likely to have devastating effect on the whole system.
* The first is how to program a large set of fine-grained services running in par-allel. The second is the need for a lightweight facility to enable MS to communicate with each other. And, finally, it needs a deployment mechanism and facility that enable ser-vices to be deployed flexibly and uninterruptively. This pa-per proposes a programming language solution to all these problems.
* For a long time, the virtual machine (VM) has been the main protagonist of cloud computing. A VM is a heavy-weight solution;
* Its main advantage is flexibility. It ena-bles services to be executed on a VM regardless of the operating system and hardware platform beneath it. Howev-er, a VM consumes system resources, so that it becomes inefficient to deploy many VMs on one server. In other words, the VM has become a bottleneck for MS.
* Container is a new technology, which overcomes the shortage of VMs.
* In summary, existing work on supporting MS has been focused on the deployment mechanism that enables MS to be easily duplicated and relocated on different servers to achieve system efficiency. These container technologies are more efficient than virtual machines because running thou-sands of containers on one virtual machine has less runtime overhead than running thousands of virtual machines,
* Our proposed solution is to develop a programming lan-guage that constructs service-oriented systems with MS as the basic building blocks that can be easily deployed to dif-ferent servers with a light-weight runtime environment simi-lar to the Java Virtual Machine.
* Here, agents means service providers just like in the real world where estate agents provide services in buying and selling proper-ties, and travel agents provide services in buying and selling air-tickets.
* In the literature, the word “service” in service-oriented architectures, and similarly its corresponding notion of “mi-croservice” in the MS architecture, has two meanings. First,a service is the functionality provided by a computer system and delivered to the users [15]. Second, the word service also refers to the computational entities that provide the ser-vices in the first sense. Here, we separate these two concepts by using the word service only to refer to the functionalities that a computational system provides, while the computa-tional entities that provide such functionality are called “agents”. By doing so, an analogy between service-orientation and object-orientation can be made clearly. Con-sequently, our programming language bears a similarity to OO programming languages.
* Moreover, by separating these two meanings of the word service, it facilitates the study of service-oriented software architectures as concerned with the composition of entities into a certain structure. This is particularly important in the study of MS architecture.
* In the context of the MS architecture, the notion of “MS” also bears two further meanings: first, MS are identical cop-ies of a service where each copy is a runtime computationalentity. Second, a MS is a template from which instances can be generated and deployed to different servers. As we will see below, our agents are autonomous, encapsulating data, operations and behavior rules, executing in parallel and co-operating with each other via asynchronous communications through a set of well-defined communication channels. These characteristics are exactly what MS services are when the word bears the meaning of computational entities.
* Like OO programming languages, CAOPLE also pro-vides an inheritance mechanism to enable “polymorphism”, i.e. agents with a number of variant functions, internal struc-tures and behaviors.
* Similar to OO, an agent may have a number of other agents (i.e. MS) as its components.
* CAOPLE provides a set of language facilities that support flexible and secure, but lightweight, communications for event-driven parallel and distributed programming that are transparent to the network structure.
* CAOPLE’s language facility supports the following communication and concurrent programming mechanisms:
  * Subscribe-and-Publish: The observe-clauses in a caste declaration actually define the communication ports that an agent listens to. It is similar to the subscribing part of the widely used subscribe-and-publish communication mechanism.
  * Event-Driven Computation: An event is generated and a “message” is sent out by an agent when it performs a public action.
  * Prevention of Data Race: As mentioned in Section 3.2, an agent’s state variables can only be modified by the agent itself. Because each agent is one thread, this prevents write-write type of data race.
  * Deployment Mechanism: An automated deployment mechanism is one of the key features of container technology.
  * Control of Communication Security: Only the message/event associated with performing a public action or the value of a public state variable are observable by other agents in the environment. To support the control of communication security, an action statement can specify a restriction on the target agents that the event is to be deliv-ered to.

# [@Yon86] Object-oriented concurrent programming ABCL/1

* Parallelism is ubiquitous in our problem domains.
* by using various metaphors found in such systems
* Each object in our computation model has its own (autonomous) processing power and it my have its local persistent memory,thecontentsofwhichmpcesentitsstate.Anobjectis always in one of three modes: dormant, active, or waiting. An object is initially dormant. It becomes active when it receives a message that satisfies one of the specified patterm and constraints.
* When an active object completes the sequence of actions that are performed in response to an accepted message, if no subsequent messages have arrived, it becomes dormant again. An object in the active mode sometimes needs to stop its current activity in order to wait for a message with specified patm'ns to arrive. In such a case, an active object changes into the waiting mode. An object in the waiting mode becomes active again when it receives a n~quired message.
* Thus message passing takes place in a point-to-point (object-to-object)fashion.No message can be broadcast.
* [Assumption for Preservation of Transmission Ordering]When two messages are sent to an object T by the same object O, the temporal ordering of the two message transmissions (according to O's clock) must be preserved in the temporal ordering of the two message arrivals (according to T's clock).
* This assumption was not made in the Actor model of computa-tion. Without this, however, it is difficult to model even simple things as objects.

# [@Yon14] My Early Education and Concurrent Objects

* Carl and his group member were interested in
  –finding a universal model for concurrent computation, and
  –the abstraction and simulation of activities for almost all entities which interact with each other and are able to move around in physical spaces.
* The entire research group was convinced that the basic entities in the model should be process- or procedure-like things that mutually interact with message passing. Message passing is required to be asynchronous in the sense that an entity can send a message to another entity anytime, even when the destination entity is not ready or able to receive the message.
* However, these notions of objects did not deal with message transmissions which take place among objects. Of course, the interactions among objects were called message passing, but they were merely meant to be dynamically dispatched method calls (or procedure calls). A more restricted formal cal-culus of modeling message passing objects was proposed by Robin Milner [7].
* In our approach, the domain to be modeled/designed/implemented is represented as a collection of concurrent objects, and the interaction of the domain components is represented as concurrent message passing among such concurrent objects.
* an intuitive characterization of concurrent objects (COs) below. Each CO
  – has a globally unique identity/name,
  – may have a protected, yet updatable local memory,
  – has a set of procedures that manipulates the memory,
  – receives a message that activates one of the procedures,
  – has a single FIFO queue for arrived messages, and
  – has autonomous thread(s) of control.

[BIB]