
Implementation {#ch-implementation}
============================



~ Epigraph { caption: "Eric S. Raymond"}
Every good work of software starts by scratching a developer's personal itch.
~


In this chapter we cover the practical aspects of programming with actors and microservices. Section [#sec-scenario] describes a scenario for a concurrent system. Section [#ch-actor-impl] covers the strategies we apply to implement this scenario using the actor model. Subsequently, Section [#ch-microservice-impl] describes the implementation of the scenario using the microservice model.


## Concurrent System Scenario {#sec-scenario}


In this section, we outline a domain-specific search engine we call *Echo*[^fn-echo-name]. This search engine is our non-trivial example of a concurrent system that serves us as the reference for evaluating the programming of concurrency with actors and microservices.

[^fn-echo-name]: The name "Echo" was chosen for its wonderful characteristics of providing a short package name and the analogy to *recalling spoken words*.  

Search engines are a composition of rather loosely coupled and independent subsystems [@Cou05]. [A user makes use of]{.red} a search engine by submitting a search request via a so-called *query*. The search engine then presents the user with respective results. This functionality however is merely the so-called retrieval phase performed by the *Retrieval subsystem*. As the name indicates, this phase retrieves information. Subsequently, the information must have been collected and stored beforehand. A second so-called *Indexing subsystem* is responsible of gathering the information and storing it in a form that is optimized for searching, a so-called *index* [@Lil09;@Ped06].

Several factors contribute to the fact that search engine architectures are suitable for concurrent programming research. First, both subsystems are mostly independent. They merely make use of a common information index, where the Indexing subsystem is exclusively adding information and the Retrieval subsystem is exclusively reading the information. Hence, the subsystems are independent and can run concurrently. Second, since many kinds of search engines regard very large amounts of data, their construction was always led be the effort to leverage concurrency in order to improve their scalability. Especially the parallel and distributed computing research has meritted attention to search engines, for example to explore cluster architectures [@Ped06;@Man08]. Additionally, our specific domain we outline below is also very suitable for concurrent processing.

The design of search engine architectures is generally led by two basic requirements [@Man08]:

* Effectiveness
  : The quality of search results is the *effectiveness* of a search engine. Effectiveness is the sole concern of the scientific discipline called *information retrieval* (IR). *Precision* and *recall* are the two metrics that IR distinguishes in order to assess the effectiveness. 

* Efficiency
  : Factors like the response time and the throughput determine the *efficiency* of a search engine. These factors are highly affected by the concurrent processing capabilities of the system.

The optimization of effectiveness is not within the scope of this thesis. We therefore merely apply a basic scoring method provided by the utilized information retrieval library for determining search results. Our sole goal is to increase the efficiency of the system by leveraging concurrent programming techniques.


### Domain Description


We build our domain specific search engine for the *podcast* domain. On the one hand, the term is used to refere to an episodic series of digital media. The media is usually audio, more seldomly video.  On the other hand, "podcast" can also refer to the distribution mechanism. The distribution builds upon XML (E__x__tensible __M__arkup __L__anguage) web feeds. RSS 2.0 [@Win03] (__R__ich __S__ite __S__ummary) or Atom [@RFC4287] are the established syndication formats. Since RSS 2.0 has always been the more dominantly used format, we keep referring to simply *RSS feeds* from here on. Both formats gained popularity in the 2000s as an effective, decentralized mechanism to publish the updates to a website's content. Podcasts build upon the same principle, but utilize an otherwise optional field for items of an RSS feed, the `<enclosure>` tag. This tag provides an URL (__U__niform __R__esource __L__ocator) to the media file. Subscribers to the feed can download the file behind the URL and listen/watch to the media, usually through a specialized software application. The `<enclosure>` is therefore the main content of each item in a podcast RSS feed. Additionally, there are other fields within the feed. Some of these fields contain human readable information about the linked media file, so-called *metadata* [@Pat06]. Appendix [#ch-benchmark-feed] gives an example of the XML feed structure with dummy metadata.

Our search engine is designed to regularly analyze RSS feeds for podcasts. The metadata allows us to add information for every media file to the search index. Although we do not analyze the media itself, we can still provide search functionality based on the metadata information. The domain is very suitable for concurrent processing, since the RSS feed files are decentralized. Every podcast content creator is publishing a separate feed. There is no interrelation between feeds. We can process each feed separately and therefore concurrently.


### System Components


At the core, the basic architecture and the components are inspired by the work of Brin & Page [@Brin98] on large scale web search engine "anatomy", as well as more modern interpretations of associated design principles given in [@Cou05] and [@Ped06].  

The two high-level subsystems we've given above, indexing and retrieval, are internally composed of several smaller components. We specifiy that each of these components has to be a concurrent task units of the programming model, i.e.\ an actor or a microservice. The respective units are:  

* CatalogStores (C)
  : hold a catalog of all information we ever gathered, that is the metadata about podcasts, their respective feeds and episodes. This information is persisted in relational databases based on a simple, straightforward domain model.

* IndexStores (I)
  : hold the data structure we use for searching, the so-called *reverse index*. Registered information entities are called *documents*. Each document relates to one podcast or episodes. A reverse index maps the previous *document-term* relationship into a *term-document* structure [@Man08]. IndexStores merely hold the information we need to match search queries to matching documents. The relevant metadata comes from the XML feeds and relates to e.g.\ title, subtitle, multiple general information tags (`<description>` or `<content:encoded>`), as well as if available the chapter marks and transcripts of episodes. 

* Web Crawlers (W)
  : aquire the information stored by the search engine, hence they download data from URLs. These URLs can relate to feeds, general websites, or APIs of other existing directories which can be used to discover new feeds. A major concern of web crawlers in general is robustness against the perils of the web [@Man08].

* Parsers (P)
  : transform the acquired information into internal representation formats by analyzing feed XML data. The extracted data is what we take into account when running search queries and subsequently display in the Web application. An important requirement on parsers is robustness regarding flawed information, because all considered data is encoded in a markup language, viz.\ XML or HTML.

* Searchers (S)
  : are tasked with performing search operations. However, they merely apply some basic query pre-processing themselves and delegate the retrieval of relevant documents to an IndexStore using its inverted index. The respective results are communicated back via the Searcher to the Gateway.

* Gateway (G)
  : provides the link for the web interface to the system internal capabilities. It exposes a REST interface to the outside and uses respective mechanisms to interact with other internal system components. The REST interface allows us to request cataloged information or perform searches. Therefore, the Gateway communicates with either a CatalogStore, or a Searcher. 

* Updater (U)
  : determines which feeds to re-download next in order to register new episodes, and update existing metadata, and discovery new feed from existing directories, on a regular basis. To ensure consistency, only one unit must exist within the system (singleton). 

Task units ending in *\*Store* are stateful, all others stateless. The components form the complete architecture of our search engine by the interaction model according to Figure [#fig-task-units].

~ Figure { #fig-task-units; caption: "Task unit interaction model of the Echo search engine"; width:100%; margin-right: 1ex; }
![img-task-units]
~

[img-task-units]: graphics/interaction-model.[svg,png] "Image about task units and message flow" { height:4.5cm; vertical-align:middle; padding-bottom:1em; margin-top:0; padding-top:0;}

When we discuss dataflow examples in due course, we use the following shorthand notation for arbitrary components `X` and `Y`, that will be substituted with the component abbreviations (`C`, `I`, `W`, `P`, `S`, `G`, `U`). `X` &rarr; `Y` is expressing `X` sending a message to `Y` (push), while `X` &larr; `Y` denotes `X` fetching a message from `Y` (pull). `X` &rightleftarrows; `Y` is short for `X` sending a request message to `Y` which in turn replies with a response (synchronous call, RPC).

The system shown by Figure [#fig-task-units] merely forms the concurrent indexing and retrieval system. It is therefore a backend application only. In order to actually use the search engine, we provide the backend with a web-based user interface (UI). This *Web* application is based on the Angular [@GoogleAngular] framework. 

The actor-based as well as the microservice-based backend implementation has to provide a REST interface within the Gateway component to allow interaction from the outside. The Web UI serves us as the proof of concept for the desired functionality of the engine's backend implementations.

Since our scientific focus is on the concurrent programming aspect and not the information retrieval aspect, we want to implement the domain specific logic only once. Therefore, we provide each backend with a common *Core* library written in Java. The Core offers most domain-specific functionality, so that each backend codebase can focus on the concurrent execution and interaction. For example, the actual searching is done through a specialized data structure, the reverse index. We use Lucene [@ApacheLucene] to create this structure. Lucene offers a Java interface that is interoperable with most JVM-based programming languages. RSS/Atom feed parsing is done using ROME [@ROME], enriched by an extension we wrote to support additional *Simple Chapter* [@PotloveSimpleChapters] metadata information.


### Subsystem Processing Pipelines {#sec-subsystem-pipelines}


In this section, we give a brief outline of the data processing pipelines which make up the two subsystems. The processing pipelines are resulting from the composition of the architecture components.

Note that Figure [#fig-task-units] shows an interaction between the Gateway and the CatalogStore. The pipelines below do not mention this interaction. The Web UI can display the entire metadata of an item. Therefore we must retrieve the complete metadata from the CatalogStore. For search requests, the Retrieval subsystem merely produces the reduced metadata for the results that is stored in the search index. We nevertheless show the `G` &rightleftarrows; `C` call for completeness.


#### Indexing Pipeline


~ Figure { #fig-indexing-pipeline; caption: "Indexing pipeline"; width:100%; }
![img-indexing-pipeline]
~

[img-indexing-pipeline]: graphics/pipeline-indexation.[svg,png] "Image about indexing pipeline" { height:3.5cm; vertical-align:middle; padding-bottom:1em; }

Feeds get either processed when they are initially indexed, or updated to check for new episodes. Hence, processing is either triggered by adding a yet unknown feed, or on demand by the Updater. In order to determine which feeds require an update, the Updater regularly inquires the database of the CatalogStore. The Updater passes the updating candidates to the Web Crawler, which fetches the XML data of the feed via HTTP. The Crawler passes the raw feed data to the Parser. The Parser extracts the podcast and episodes metadata from the XML. All metadata is then forwarded to the CatalogStore. The database of the Store persists the complete metadata. Additionally, the Catalog has to determine based on an episode's metadata record if the episode is already registered, or a new entry. The Catalog finally sends the search-relevant part[^fn-relevant-metadata] of the metadata to the IndexStore, where it is added to the Lucene index data structures. The overall flow is: `U` &rarr; `C` &rarr; `U` &rarr; `W` &rarr; `P` &rarr; `C` &rarr; `I`

[^fn-relevant-metadata]: Some parts of the metadata, like the byte size or MIME type of the `<enclosure>` file, is important to determine new entries. Therefore the CatalogStore persist this data. This metadata is however hardly relevant for search queries, therefore we do not include it in the search index. 


#### Retrieval Pipeline


~ Figure { #fig-retrieval-pipeline; caption: "Retrieval pipeline"; width:100%; }
![img-retrieval-pipeline]
~

[img-retrieval-pipeline]: graphics/pipeline-retrieval.[svg,png] "Image about retrieval pipeline" { height:1.5cm; vertical-align:middle; padding-bottom:1em; }

The essential purpose of the engine is search. The Web UI offers an interface similar to well-known search providers on the world wide web. The Gateway registers search requests by the UI on the REST interface and forwards the request to a Searcher (`G` &rarr; `S`). This Searcher is doing some basic query processing and then forwards the resulting query to an IndexStore (`S` &rarr; `I`). 

The IndexStore propagates the found results back via the Searcher (`I` &rarr; `S`) and the Gateway (`S` &rarr; `G`) to the Web UI. This message flow has to happen in a timely manner, thus synchronous. The complete flow is: `G` &rightleftarrows; `S` &rightleftarrows; `I`.



<!--
Minor work flows:

* Exploring the Catalog
  : The search engine provides besides searching index data records also a database of all known podcast and episode metadata. The web UI offers basic support for exploring such data, e.g.\ by viewing info pages for podcasts or episodes. Thus, REST requests have to be forwarded from the Gateway to the CatalogStore (`G` &rightleftarrows; `C`) in a timely fashion.

* Adding and updating feeds
  : Feeds can be proposed so that the engine will check whether it is already known and issue an indexation if not. Proposing can either be done manually by a user, or as a result of crawled data from existing directories. Thus the Updater issues regular crawling for supported Podcast directories.

...

For example, the initial fetching or updating of a feed, and subsequent processing of the feed's data involves nearly all system components. Updating is a regular task. In a large enough database of feeds, we can expect that nearly all the time there is an update in progress. These update tasks however should not interfere or limit other regular tasks, especially those with time constraints. All user interactions is constraint by time, therefore [ACHTUNG: hier habe ich den satz verändet, daher liest sich das jetzt so als würde sich die sync. und trans. negation of die time constraint tasks beziehen]{.red} synchronization or transactions are generally an undesirable and less expedient path  [@Cou05].
-->




<!--
### Scope and Limitations

~ todo
Hier beschreiben was die Implementierungen leisten können sollen, und was nicht
~

~ green
* static configuration of components
  * KEINE elasticity
  * KEINE mobility at runtime 
  * keine notwendigkeit von event sourcing
~

~ todo
Hier könnte eine hübsche +/- Tabelle stehen
~
-->