# [@Roe15] Akka in Action (Book)


* Most general-purpose programming languages are written in sequence (Scala and
Java being no exception to the rule). A concurrent programming model is required to
bridge the gap between sequential definition and parallel execution.
* Whereas parallelization is all about executing processes simultaneously, concur-rency concerns itself with defining processes that can function simultaneously, or can
overlap in time, but don’t necessarily need to run simultaneously. A concurrent system
is not by definition a parallel system. Concurrent processes can, for example, be exe-cuted on one CPU through the use of time slicing, where every process gets a certain
amount of time to run on the CPU, one after another.
* The JVM has a standard concurrent programming model (see figure 1.14), where,
roughly speaking, processes are expressed in objects and methods, which are executed on threads.
* Fault tolerance
    * Let's recap the benefits of the let-it-crash approach:
        * Fault isolation—A supervisor can decide to terminate an actor. The actor is removed from the actor system.
        * Structure—The actor system hierarchy of actor references makes it possible to replace actor instances without other actors being affected.
        * Redundancy—An actor can be replaced by another. In the example of the bro-ken database connection, the fresh actor instance could connect to a different database. The supervisor could also decide to stop the faulty actor and create another type instead. Another option would be to route messages in a load-balanced fashion to many actors, which will be discussed in chapter 9.
        * Replacement—An actor can always be re-created from its Props. A supervisor can decide to replace a faulty actor instance with a fresh one, without having to know any of the details for re-creating the actor.
        * Reboot—This can be done through a restart.
        * Component lifecycle—An actor is an active component. It can be started, stopped, and restarted. In the next section, we’ll go into the details of how the actor goes through its lifecycle.
        * Suspend—When an actor crashes, its mailbox is suspended until the supervisor decides what should happen with the actor.
        * Separation of concerns—The normal actor message-processing and supervision fault recovery flows are orthogonal, and can be defined and evolve completely independently of each other.
* Message channels
    * Channel Type: Point to Point
        * A channel transports the message from the sender to the receiver. The point-to-point channel sends the message to one receiver.
        * It’s possible for a point-to-point channel to have multiple receivers, but the channel makes sure that only one receiver receives the message. The round-robin router in section 9.2.1 is an example of a channel having multiple receivers. The processing of the messages can be done concurrently by different receivers, but only one receiver consumes any given message. This is shown in figure 10.2.
    * Channel Type: Publish-Subscribe
        * You’ve seen in the previous section that the point-to-point channel delivers each mes-sage to only one receiver. In these cases the sender knows where the message has to be sent. But sometimes the sender doesn’t know who is interested in the message. This is the greatest difference between the point-to-point channel and the publish-subscribe channel. The channel, instead of the sender, is responsible for keeping track of the receivers who need the message. The channel can also deliver the same message to multiple receivers.
* Cluster
    * Clustering takes location transparency to the next level.
    * The ultimate goal for the cluster module is to provide fully automated features for actor distribution, load balancing, and failover. Right now the cluster module sup- ports the following features:
        * Cluster membership—Fault-tolerant membership for actor systems.
        * Load balancing—Routing messages to actors in the cluster based on a routing algorithm
        * Node partitioning—A node can be given a specific role in the cluster. Routers can be configured to only send messages to nodes with a specific role.
        * Partition points—An actor system can be partitioned into actor subtrees that are located on different nodes
        * A single-purpose data processing application is a good example of a candidate application for using clusters, for example, data processing tasks like image recogni-tion or real-time analysis of social media. Nodes can be added or removed when more or less processing power is required. Processing jobs are supervised: if an actor fails, the job is restarted and retried on the cluster until it succeeds.
        * Manually joining cluster nodes
            * The seed nodes feature is not required; you can create a cluster manually by starting a node that joins itself. Subsequent nodes will then have to join that node to join the cluster, by sending it a Join message. This means that they’ll have to know the address of the first node, so it makes more sense to use the seed functionality. There are cases where you can’t know IP addresses or DNS names of servers in a network beforehand. In those cases, there are three choices that seem plausible:
            * Use a list of known pure seed nodes with well-known IP addresses or DNS names, outside of the network where host name addresses can’t be prede-termined. These seed nodes don’t run any application-specific code and purely function as a first point of contact for the rest of the cluster.
            * Get your hands dirty building your own zero-configuration cluster discovery protocol that fits your network environment. This is a non-trivial task.
            * Use existing service discovery/registry technology like Apache ZooKeeper, HashiCorp Consul, or CoreOs/etcd and add some “glue.” Instrument every cluster node with some code to register itself with the discovery service on startup and write an adapter that gets the currently available cluster nodes from a service like this to connect to the cluster.
        * Mind you, a ZooKeeper solution will still require a full set of host and port combina-tions, so you’re trading in one well-known set of addresses for another. This is also not as trivial as it sounds, since you have to keep the discovery service up to date on the availability of every cluster node, and the discovery service might depend on a different set of trade-offs than an Akka cluster, which might not be immediately apparent. Caution is advised. (Different consistency models will probably apply and your mileage may vary on experience in identifying these trade-offs.)
    * Failure detector
        * The cluster module uses an implementation of a accrual failure detector to detect ϕ unreachable nodes. The work is based on a paper by Naohiro Hayashibara, Xavier Défago, Rami Yared, and Takuya Katayama.a Detecting failures is a fundamental issue for fault tolerance in distributed systems.
        * The ϕ accrual failure detector calculates a value on a continuous scale (called a ϕ (phi) value) instead of determining a Boolean value indicating failure (if the node is reachable or not). From the referenced paper: “Roughly speaking, this value captures the degree of confidence that a corresponding monitored process has crashed. If the process actually crashes, the value is guaranteed to accrue over time and tend toward infinity, hence the name.” This value is used as an indicator for suspecting that something is wrong (a suspicion level) instead of determining a hard-and-fast yes-or-no result.